% Hopf Algebras and Combinatorics

\documentclass{article}
\usepackage[paperwidth=5.9in, paperheight=9in, top = 20mm, bottom = 15mm, left=8mm, right = 8mm]{geometry}

\usepackage{natbib}

\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage[all, cmtip, 2cell]{xy}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{xspace}

\usepackage[english]{babel}
\usepackage{tgtermes}
\usepackage[T1]{fontenc}

\usepackage{url}

\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{Definition}{Definition}
\newtheorem*{Definition*}{Definition}
\newtheorem{Example}{Example}
\newtheorem*{Example*}{Example}

\theoremstyle{remark}
\newtheorem*{Remark*}{Remark}

\newtheoremstyle{underline}% name
{}        % Space above, empty = `usual value'
{}              % Space below
{}              % Body font
{}    % Indent amount (empty = no indent, \parindent = para indent)
{}              % Thm head font
{:}             % Punctuation after thm head
{1.5mm}         % Space after thm head: \newline = linebreak
{\underline{\thmname{#1}\thmnumber{ #2}\thmnote{(#3)}}}  % Thm head spec

\theoremstyle{underline}
\newtheorem*{Multiplication*}{Multiplication}

\theoremstyle{underline}
\newtheorem*{Comultiplication*}{Comultiplication}

\DeclareMathOperator{\Mat}{Mat}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}

\let\Im\relax
\DeclareMathOperator{\Im}{Im}
\newcommand{\id}{\mathrm{id}}
\renewcommand{\th}{\textsuperscript{th}\xspace}

\setlength{\parindent}{0pt}

\begin{document}
	
	\title{\textbf{Hopf Algebras and Combinatorics}}
	
	\author{\small Arjit Seth and M. Vinay \\ \small Manipal Institute of Technology, Manipal University}
	\date{}
	\maketitle
	
	\renewcommand{\abstractname}{Context}
	\begin{abstract}
		These are notes created based on the lectures by Prof. Federico Ardila at San Francisco State University. Hopf algebras seem to be a difficult topic to introduce as a simple definition. They apparently have applications in quantum field theory, pertinent to Feynman diagrams.
	\end{abstract}
	
	\begingroup
	\let\clearpage\relax
	\tableofcontents
	\endgroup
	
	\medskip
	\medskip
	
	\section{Introduction}\label{sec:Intro}
	A Hopf algebra is a complicated mathematical structure with a definition involving lots of properties and scary commutative diagrams. It fundamentally invokes the tensor product, and it is difficult to construct as a complete definition in one sitting, so we must start with smaller definitions and build up the structure progressively.
	
	\begin{Definition}[Hopf algebra]\label{def:HopfAlg}
		A \emph{Hopf algebra} $H$ is a $\mathbb{K}$-vector space with five operations:
		\begin{center}
			\begin{tabular}{rl}
				Multiplication: &   $ m\colon H \otimes H \to H$\\
				Unit: & $u\colon \mathbb{K} \to H $ \\
				Comultiplication: & 	$ \Delta\colon H \to H \otimes H$\\
				Counit: & $\epsilon\colon H \to \mathbb{K}$ \\
				Antipode: &  $ S\colon H \to H $
			\end{tabular}
		\end{center}
	\end{Definition}
	
	These definitions invoke lots of commutative diagrams that are difficult to \TeX, so they'll be shown later once a better understanding is developed. Now we must preliminarily define the tensor product.
	
	\begin{Definition}[Tensor product]\label{def:TensorProd}
		Let $\mathbb{K}$ be a field, and let $V$ and $W$ be vector spaces over $\mathbb{K}$. The tensor product $ V\otimes W $ is a vector space over $ \mathbb{K} $ generated by vectors $v \otimes w$, $v \in V$, $w \in W$, and satisfying the following properties:
		\begin{center}
			Distributivity over addition: \hfill $ (v + v') \otimes (w + w') = v \otimes w + v \otimes w' + v' \otimes w + v' \otimes w'$\\
			Scalar multiplication independent of two arguments: \hfill $ \lambda(v \otimes w) = \lambda v \otimes w = v \otimes \lambda w$
		\end{center}
	\end{Definition}
	
	The combination of these is a property called \emph{bilinearity}. Note that this vector space is much larger than the product space $V \times W$:
	\begin{align*}
	\dim U \times V & = \dim U + \dim V\\
	\dim U \otimes V & = \dim U \dim V
	\end{align*}
	This is intuitively obvious because the tensor product defines an \emph{actual} product between elements of $V$ and $W$, instead of a restricted component structure induced by a Cartesian product, which constrains manipulations to $V$ and $W$ independently.
	
	\begin{Example*}[Tensor product of bases]
		If $ \qty{v_i}_{i \in I}$ and $ \qty{w_j}_{j \in J} $ are bases of $V$ and $W$, then $ \qty{v_i \otimes w_j \mid i \in I, \; j \in J}$ is a basis for $V \otimes W$. Let $ \qty{v_i}$ and $\qty{w_j} $ be the standard bases in two and three dimensions, represented as column and row vectors respectively. One element of the basis for the tensor product is:
		\begin{gather*}
		v_1 \otimes w_3 = \mqty[1 \\ 0] \otimes \mqty[0 & 0 & 1]  = \mqty[0 & 0 & 1 \\ 0 & 0 & 0]
		\end{gather*}
		It is clear that this construction develops the standard basis for $V_{2} \otimes W_{3}$.
	\end{Example*}
	
	\begin{Example*}[Polynomial ring and matrices] 
		Let $ V = \mathbb{R}[x]$ and $ W = \Mat_{2\times 2}(\mathbb{R})$. A formal expression of an element in $V \otimes W $ is, for example, $(2 + 2x) \otimes \mqty[0 & 1 \\ 1 & 0]$.
	\end{Example*}
	
	\begin{Example*}[Dirac matrices]
		The following anticommutation relations have a corresponding matrix representation called the Pauli matrices:
		\begin{gather*}
		\sigma_i^2 = I_2, \;\; \sigma_i \sigma_j + \sigma_j\sigma_i = 0, \; i \neq j \\
		\sigma_1 = \mqty[0 & 1 \\ 1 & 0],\; \sigma_2 = \mqty[0 & -i \\ i & 0],\; \sigma_3 = \mqty[1 & 0 \\ 0 & -1]
		\end{gather*}
		To develop the relativistic theory of the electron, Dirac constructed $4 \times 4$ matrices $\gamma^\mu,\; \mu = 0,1,2,3$, out of the Pauli matrices using tensor products. The details are not relevant, so we will just display the results:
		\begin{gather*}
		\gamma \coloneqq \mqty[0 & 1 \\ -1 & 0] \\
		\gamma^{0} = \sigma_3 \otimes I_2 = \mqty[I_2 & 0 \\ 0 & -I_2] = \mqty[1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & -1 & 0 \\ 0 & 0 & 0 & -1] \\
		\gamma^{i} = \gamma \otimes \sigma_i = \mqty[0 & \sigma_i \\ -\sigma_i & 0],\;\; i = 1,2,3
		\end{gather*}
		The Pauli and Dirac matrices form Clifford algebras respectively.
	\end{Example*}
	
	\subsection{Motivating Examples for Hopf Algebras}
	
	\begin{Example}[Groups]
		Let $G$ be a \emph{finite group} and $\mathbb{K}$ a \emph{field}. To allow multiplication of scalars into the group, define the group ring:
		\begin{gather*}
		H = \mathbb KG = \qty{\, \sum_{i = 1}^n\lambda_i g_i \biggm| n \in \mathbb N,\; \lambda_i \in \mathbb K,\; g_i \in G \,}	
		\end{gather*}
		with the ring multiplication	$g \cdot h= gh$, the group multiplication. Extending this linearly:
			\begin{gather*}
			\pqty{\sum_{i = 1}^{n}\lambda_i g_i}\pqty{\sum_{j = 1}^{p}\mu_j h_j} = \sum_{i = 1}^n \sum_{j = 1}^p \lambda_i \mu_j(g_i h_j)
			\end{gather*}
		
		\begin{Comultiplication*}
			$ \Delta(g) = g \otimes g $. Extending this linearly:
			\begin{gather*}
			\Delta\pqty{\sum_{i = 1}^n \lambda_ig_i} = \sum_{i = 1}^n \lambda_i(g_i \otimes g_i)
			\end{gather*}
			These definitions do give a Hopf algebra according to the lecturer. 	
		\end{Comultiplication*}
		
		\begin{Remark*}
			The comultiplication $ \Delta(g) = 1 \otimes g + g \otimes 1 + g \otimes g$ should also be valid, as the mapping \emph{should} point to all possible information of where $g$ can come from. As we will see later, this idea will be partially evident in future definitions of different structures.
		\end{Remark*}
		
	\end{Example}
	
	
	\begin{Example}[Polynomial rings]
		Let $H = \mathbb{K}[X]$, the \emph{polynomial ring}.
		
		\begin{Multiplication*}
			$m\pqty{X^i \otimes X^j} = X^{i+j}$. Extending this linearly:
			\begin{gather*}
			m\pqty{\sum_{i = 0}^n \alpha_i X^i \otimes \sum_{j = 0}^p \beta_j X^j} = \sum_{i = 0}^n \sum_{j = 0}^p \alpha_i \beta_j X^{i+j},\;\; \forall\,\alpha_i,\beta_j \in \mathbb K,\; \forall\,	n, p\in \mathbb N
			\end{gather*}
		\end{Multiplication*}
		
		\begin{Remark*}
			This is a commutative multiplication because $X^{i + j} = X^{j + i}$.
		\end{Remark*}
		
		\begin{Comultiplication*}
			Extending the logic from groups:
			\begin{gather*}
			\Delta\pqty{X} = \pqty{1 \otimes X} + \pqty{X \otimes 1}
			\end{gather*}
		\end{Comultiplication*}
		
		\begin{Remark*}
			The combination $\pqty{X \otimes X}$ is not included here probably because the addition of ring elements is analogous to multiplication of group elements, justifying $g \otimes g$ in the definition for groups. \\
		\end{Remark*}
		
		This ring already has a multiplicative structure, which the coproduct should obey naturally:
		\begin{gather*}
		\Delta\pqty{X^2} = \bqty{1 \otimes X + X \otimes 1} \cdot \bqty{1 \otimes X + X \otimes 1} \\
		= 1 \otimes X^2 + 2\pqty{X\otimes X} + X^2 \otimes 1 
		\end{gather*}
		This suggests the following extension:
		\begin{gather*}
		\Delta\pqty{X^{n}} = \sum_{i}^{n} \binom{n}{i}\pqty{X^{i} \otimes X^{n-i}} 
		\end{gather*}
		Notice the following, which shows the information about the coefficient of a comultiplication:
		\begin{gather*}
		m\pqty{\Delta\pqty{X^n}} = \sum_{i=1}^{n} \binom{n}{i}X^n =  2^nX^n
		\end{gather*}
		
	\end{Example}
	
	\begin{Example}[Graphs]
		Let $[G]$ be the \emph{isomorphism class of the graph} $G = (V,E)$. The collection of all isomorphic graphs is denoted by $L = \qty{\, [G] \mid \; G \in \cal G \,}$, where $\cal G$ is the class of all graphs. Define the vector space $H = \mathbb KL$, in which the elements are linear combinations of graphs:
		\begin{gather*}
		H = \qty{\, \sum_i k_i[G_i]\,\bigg|\;k \in \mathbb K,\; G \in \cal G\,}	
		\end{gather*}
		
		\begin{Multiplication*}
			Defined most naturally as a disjoint union of the arguments as components of the graph, which is commutative:
			\begin{equation}
			m\mqty(\;
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					\node (n1) at (1,0)	{};
					\node (n2) at (1.5,1)	{};
					\node (n3) at (2,0)	{};
					\foreach \from/\to in {n3/n2, n2/n1}
					\draw (\from) -- (\to);
			}}\,
			\otimes\,
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}}\;)
			= \mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					\node (n1) at (1,0)	{};
					\node (n2) at (1.5,1)	{};
					\node (n3) at (2,0)	{};
					\foreach \from/\to in {n3/n2, n2/n1}
					\draw (\from) -- (\to);
				}&
				\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}}
			\end{equation}
		\end{Multiplication*}
		
		\begin{Comultiplication*}
			Not entirely obvious, but a satisfactory definition can be deduced from the previous examples and observations. The comultiplication of an element is essentially the sum of all of its possible decompositions into two complementary subelements.\\
			This idea can be implemented in this algebra as well by selecting a subset $S$ of the vertex set of the graph $V(G)$ and taking the tensor product of the graphs induced by $S$ and its complement $V(G) - S$ (a graph induced by a subset of the vertex set consists of vertices in that subset and all of the edges between these vertices that occur in the original graph). This is shown by (dropping the isomorphism class notation for brevity):
			\begin{gather*}
			\Delta(G) = \sum_{S \subseteq V(G)} G\big|_S \otimes G\big|_{V(G) - S}
			\end{gather*}
			This is illustrated using the following example:
			\begin{gather*}
			\Delta
			\mqty(\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
			{
				\node (n4) at (5,0.6)	{};
				\node (n5) at (5,0)	{};
				\node (n6) at (6,0.6)	{};
				\node (n7) at (6,0)	{};
				\node (n8) at (5.5,1) {};
				\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7, n4/n8, n6/n8}
				\draw (\from) -- (\to);
			}) = 
			\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					\node (n4) at (5,0.5)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (5.3,1) {};
					\foreach \from/\to in {n4/n5, n4/n6}
					\draw (\from) -- (\to);
			}}\otimes \;
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0.3)	{};
					\foreach \from/\to in {n4/n5}
					\draw (\from) -- (\to);
			}}) + 
			\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}} \otimes\;
			\mqty{\tikz[scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n4) at (5,0)	{};
			}})\; + 
			\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n5) at (5,0)	{};
					\node (n6) at (5.5,0.5)	{};
					\foreach \from/\to in {n5/n6}
					\draw (\from) -- (\to);
			}}\, \otimes
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}}) +
			\cdots
			\end{gather*}
			The number of tensor products is easily countable as the number of subsets of $V(G)$, which is $2^n$, where $n$ is the number of vertices of the graph $G$. For the above example, there are 5 vertices, so there are 32 tensor products to be summed over.
		\end{Comultiplication*}
		
		\begin{Remark*}
			The product of the coproduct of a graph is:
			\begin{gather*}
			m\pqty{\Delta(G)} \neq G
			\end{gather*}
			This indicates that the product of the coproduct of a graph does not bring back the original argument, so $m$ and $\Delta$ are not inverse operations. (Note: This is also evident from the group and the polynomial ring examples.)
		\end{Remark*}
		
	\end{Example}
	
	\begin{Example}[Permutations]
		Let $P_n$ denote the set of all permutations of the set $\mathbb N\Mod n := \qty{1, 2, \ldots, n}$, for a given non-negative integer $n$. Let $P$ denote the set of all permutations of $\mathbb N \Mod n$, for all non-negative integers $n$ --- i.e., $P := \bigcup\limits_{n = 0}^\infty P_n$. Here are two permutations in $P$:
		\begin{gather*}
		p = \mqty(1 & 2 & 3 & 4 & 5 \\ 2 & 1 & 3 & 4 & 5), \;\; q = \mqty(1 & 2 \\ 2 & 1) 
		\end{gather*}
		
		\begin{Remark*}
			Although they might have the `same' action, they are fundamentally different elements of $P$, as $p$ is an element of $P_5$ and $q$ that of $P_2$.
		\end{Remark*}
		
		The vector space is defined as:
		\begin{gather*}
		H = \mathbb KP = \qty{\, \sum_{i = 1}^n k_i p_i \;\bigg|\; k_i \in \mathbb K,\; p_i \in P,\; n \in \mathbb N_0\,}
		\end{gather*}
		Note that the coefficients do \emph{not} denote the number of times of application of their corresponding permutations; they just depict a formal linear extension in the vector space.
		
		\begin{Multiplication*}
			An example is $(1 \, 2) \otimes (3 \, 2 \,1)$ using one-line notation (\emph{not} cycle notation):
			\begin{align*}
			m((1 \, 2) \otimes (3 \, 2 \, 1)) = & (1 \, 2 \, 5 \, 4 \, 3) + (1 \, 5 \, 2 \, 4 \, 3) + (1 \, 5 \, 4 \, 2 \, 3) + (1 \, 5 \, 4 \, 3 \, 2) + (5 \, 1 \, 2 \, 4 \, 3) + {}\\
				& (5 \, 1 \, 4 \, 2 \, 3) +  (5 \, 1 \, 4 \, 3 \, 2) + (5 \, 4 \, 1 \, 2 \, 3) + (5 \, 4 \, 1 \, 3 \, 2) + (5 \, 4 \, 3 \, 1 \, 2)
			\end{align*}
			This shows that it respects the relative order of the elements within each argument as in a riffle shuffle of cards and generates only \emph{some} permutations in $P_5$ as a result. Also note how the elements $1, 2, 3$ in the second argument were relabelled $3, 4, 5$ respectively, to ensure that we get an element of $P_5$ after shuffling. This might be represented as given below, with $u_i$ denoting the $i$\th element in the permutation $U$:
			\begin{gather*}
			m\pqty{U \otimes V} = m\pqty{\pqty{u_1\ldots u_n} \otimes \pqty{v_1\ldots v_p}} \\
			= \sum (w_1 \ldots w_{n + p})
			\end{gather*}
			Where $(w_1 \ldots w_{n + p})$ stands for every possible permutation of the resultant set with the values of $v_j$ right-shifted by $n$, under the rule that the relative orders of the elements of $U$ and $V$ respectively are not lost --- i.e., for any two $w_i$, $w_j$, $1 \le i < j \le n + p$, one of the following holds:
			\begin{enumerate}
				\item $w_i = u_k$ and $w_j = v_r + n$ 
				\item $w_i = v_r + n$ and $w_j = u_k$
				\item $w_i = u_k$ and $w_j = u_l$, with $k < l$
				\item $w_i = v_r + n$ and $w_j = v_s + n$, with $r < s$
			\end{enumerate}
			where $1 \le k, l \le n$, $1 \le r, s \le p$.
		\end{Multiplication*}
		
		\begin{Comultiplication*}
			Similar to graphs, the coproduct of permutations is obtained by cutting a line between the numbers (in one-line notation, e.g. $(1 \, 2 \mid 3\, 4\, 5)$), and writing the outer product with each piece as a component, then summing over all complementary combinations. 
			\begin{gather*}
			\Delta\pqty{u_1 u_2 \ldots u_n} = \sum_{i=0}^n \pqty{u_1\ldots u_i} \otimes \pqty{v_1\ldots v_{n - i}}
			\end{gather*}
			where $v_1, \ldots, v_{n - i}$ are obtained by relabelling $u_{i + 1}, \ldots, u_n$ respectively in such a way that the resulting set $\qty{v_1, \ldots, v_{n - i}} = \mathbb N \Mod {(n - i)}$, but preserving the relative order of elements. An example using a permutation of $P_5$:
			\begin{gather*}
			\Delta\pqty{4 \, 2 \, 5 \, 3 \, 1} = \pqty{\varnothing \otimes 42531} + \pqty{1 \otimes 2431} + \pqty{21 \otimes 321} + \cdots
			\end{gather*}
		\end{Comultiplication*}
		
		\begin{Remark*}
			Nothing so far.
		\end{Remark*}
	\end{Example}
	
	\section{Algebras Over a Field/Ring}
	
	An \emph{algebra over a field} is a structure that is simultaneously a \emph{vector space} and a \emph{ring}. The setup will be a field $\mathbb K$ and a ring $A$ with a multiplicative identity $1$, called a $\mathbb K$-algebra.
	Three definitions are introduced that will be shown to be equivalent.
	
	\begin{Definition}[$\mathbb K$-algebra]\label{def:k-Alg-1}
		$A$ forms a $\mathbb K$\emph{-algebra} if $\mathbb K \subseteq Z(A)$ and $1_{\mathbb K} = 1_A$, where $Z(A)$ is the centre of the ring.
	\end{Definition}
	
	\begin{Example*}[Polynomial rings]
		Let $A = \mathbb K[x]$. This forms a $\mathbb K$-algebra because the ring is commutative and the elements of the field in the ring are the constant polynomials, and $1_{\mathbb K}$ is the same as $1_A$. This directly generalises to the multivariate polynomial ring $B = \mathbb K[x_1,\ldots,x_n]$, $n \in \mathbb N$.
	\end{Example*}
	
	An example of a ring that is a vector space, but does not form a $\mathbb K$-algebra as per Definition~\ref{def:k-Alg-1} is $A = \Mat_{n\times n}(\mathbb K)$. This is because $\mathbb K \not\subseteq A$. However, a ``copy'' of $\mathbb K$ exists as the subfield of matrices of the form $\lambda I$, where $I$ is the identity matrix of corresponding dimensions, and $\lambda \in \mathbb K$. This structure should form a $\mathbb K$-algebra, which motivates the second definition.
	
	\begin{Definition}[$\mathbb K$-algebra]
		$A$ is a $\mathbb K$\emph{-algebra} if there is an embedding $u \colon \mathbb K \to A$ such that $u(\mathbb K) \subseteq Z(A)$ and $u\pqty{1_{\mathbb K}} = 1_A $.
	\end{Definition}
	
	\begin{Remark*}
		This allows $A = \Mat_{n\times n}(\mathbb K)$ to form a $\mathbb K$-algebra if we define $u(\lambda) = \lambda I,\, \forall \lambda \in \mathbb K$. An observation is that any $A$ now forms a $\mathbb K$-vector space because scalar multiplication is implemented as $\lambda \cdot a \coloneqq u(\lambda)a,\, \lambda \in \mathbb K,\, a \in A$. The construction of the polynomial ring $\mathbb K[x]$ as a $\mathbb K$-algebra also follows directly from this definition.
	\end{Remark*}
	
	An \emph{algebra over a ring}, by analogy, is a module and a ring with a multiplicative identity defined similarly:
	
	\begin{Definition}[$R$-algebra]
		$M$ is an $R$\emph{-algebra} if there is a ring homomorphism $u \colon R \to M$ such that $u(R) \subseteq Z(A)$ and $u\pqty{1_{R}} = 1_A $ with a left or right multiplication specified.
	\end{Definition}
	
	\begin{Example*}[$\mathbb Z$-algebra]
		A quaternion $a + bi + cj + dk$ is a \emph{Hurwitz quaternion} if $a$, $b$, $c$, and $d$ are either all integers, or all half-integers --- i.e., halves of odd integers. Let
		\begin{gather*}
		H := \qty{\, a + bi + cj + dk \,\bigg|\, a, b, c, d \in \mathbb Z\ \text{or}\ a, b, c, d \in \mathbb Z + \frac 1 2 \,}
		\end{gather*}
		be the set of all Hurwitz quaternions. Then $H$ is a $\mathbb Z$-algebra, since its centre consists of all Hurwitz quaternions with imaginary parts zero, which contains a copy of $\mathbb Z$ as a subring.
	\end{Example*}
	
	\subsection{Algebra Homomorphism}
	
	\begin{Definition}
		Let $A_1, A_2$ be $\mathbb K$-algebras. An \emph{algebra homomorphism} is $\phi\colon A_1 \to A_2$ which is a ring homomorphism and linear map simultaneously. 
	\end{Definition}
	
	\begin{Remark*}
		Observations:
		\begin{itemize}
			\item $ B \subseteq A $ is a subalgebra if $B$ is both a subspace and subring. 
			\item A structure that quotients the algebra must quotient the vector space and the ring simultaneously. A subspace quotients the vector space, and an ideal quotients the ring. All ideals form subspaces, therefore ideals quotient the algebra. 
			\item If $\phi \colon A \to B $ is a $\mathbb K$-algebra homomorphism, then $\Im \phi \cong A/\ker \phi$, where $\ker\phi$ forms an ideal $I$. This is analogous to the first isomorphism theorem for groups, rings, vector spaces, etc.
			\item The direct product of two $\mathbb K$-algebras is also a $\mathbb K$-algebra, as the vector space and ring structures are independently inherited. The tensor product also forms a $\mathbb K$-algebra.
		\end{itemize}
	\end{Remark*}
	
	\begin{Definition}[$\mathbb K$-algebra]
		A $\mathbb K$-algebra is a vector space $A$ over a field $\mathbb K$ equipped with linear maps $ m\colon A \otimes A \to A,\; u\colon \mathbb K \to A $ such that the following diagrams commute:
		\begin{equation*}
		\xymatrix{
			A \otimes A \otimes A \ar[d]_{\id \otimes m} \ar[r]^-{m \otimes \id} & A \otimes A \ar[d]^{m} \\
			A \otimes A \ar[r]_{m} & A
		} \;\;\;\;\;\;
		\xymatrix{
			\mathbb K \otimes A \ar[r]^{u \otimes \id} \ar[dr]_{f} & A \otimes A \ar[d]_{m} & A \otimes \mathbb K \ar[l]_{\id \otimes u} \ar[dl]^{g} \\
			& A &	
		}
		\end{equation*}
		where $f$ and $g$ are the natural isomorphisms $\mathbb K \otimes A \to A$, $\lambda \otimes x \mapsto \lambda x$ and $A \otimes \mathbb K \to A$, $x \otimes \lambda \mapsto \lambda x$ respectively.
	\end{Definition}
	
	\begin{Remark*} For vectors $x$ and $y$, we write $m(x, y)$ as $xy$.\\
		For the first diagram: $(m \otimes \id)(x \otimes y \otimes z) = xy \otimes z,\; m(xy \otimes z) = (xy)z $ and $(\id \otimes m)(x \otimes y \otimes z) = x \otimes y z,\; m(x \otimes yz) = x(yz)$, which shows that the multiplication $m$ is \emph{associative}:
		\begin{gather*}
		m(m(x \otimes y) \otimes z) = m(x \otimes m(y \otimes z))
		\end{gather*}
		
		For the second diagram: $(u \otimes \id) (\lambda \otimes x) = u(\lambda) \otimes x$, and $m(u(\lambda) \otimes x) = u(\lambda) x$; also, $f(\lambda \otimes x) = \lambda x$. Since the diagram commutes, $u(\lambda) x = \lambda x$. This shows that left-multiplying a vector $x$ by the vector $u(\lambda)$ is equivalent to multiplying it by the scalar $\lambda$. The same holds for right multiplication. If $1_A := u(1_{\mathbb K})$, then $1_A x = 1_{\mathbb K} x = x$ and $x 1_A = x 1_{\mathbb K} = x$, which shows that the multiplication $m$ is \emph{unitary}, with unity $1_A$.
		
		This definition is equivalent to the previous one, which can be verified by checking if the structure shares the remaining property of a ring, \emph{distributivity}, which is satisfied because of the linearity of $m$:
		\begin{gather*}
		m(u \otimes (v + w)) = m(u \otimes v) + m(u \otimes w) = uv + uw
		\end{gather*}
	\end{Remark*}
	
	\begin{Remark*}
		To show that the previous definition implies the current one, the only non-trivial construction required is $m$, which is defined as a multiplication under the previous definition: $m\colon A \otimes A \rightarrow A$ such that $ m(a \otimes b) \coloneqq ab $, this remark is a little troubling because we do not have a clear definition of the tensor product and its relations with other algebraic structures, which will be investigated now.
	\end{Remark*}
	
	\section{Tensor Products}
	
	\begin{Definition}[Free vector space]
		Let $F(V \times W) = \mathbb K\text{-}\mathrm{span}\qty{\, (v, w) \mid v \in V,\, w \in W\, }$, called the \emph{free vector space} on $V \times W$.
	\end{Definition}
	
	\begin{Definition}[Tensor product]
		The tensor product space is the quotient:
		\begin{gather*}
		V \otimes W = F(V \times W)/I
		\end{gather*}
		where $I$ is generated by linear relations:
		\begin{gather*}
		(v_1 + v_2, w) \sim (v_1, w) + (v_2, w) \\
		(v, w_1 + w_2) \sim (v, w_1) + (v, w_2) \\
		(cv, w) \sim (v, cw) \sim c(v, w)
		\end{gather*}
	\end{Definition}
	
	\begin{Remark*}
		The tensor $a \otimes b = \overline{(a,b)}$, an equivalence class, and $a' \otimes b'$ can be equal to $a \otimes b,\, a' \neq a, \, b' \neq b$.
	\end{Remark*}
	
	To define a linear $m\colon V \otimes W \to W$, we would have to define an $n\colon F(V \times W) \to W$ such that $n(I) = 0$, which implies that $n$ is a bilinear map. 
\end{document}
