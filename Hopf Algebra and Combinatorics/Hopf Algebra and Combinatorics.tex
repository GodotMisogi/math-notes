% Hopf Algebras and Combinatorics

\documentclass{article}
\usepackage[paperwidth=5.9in, paperheight=9in, top = 20mm, bottom = 15mm, left=8mm, right = 8mm]{geometry}

\usepackage{natbib}

\usepackage{amsmath, amsthm, amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{tikz}

\usepackage[english]{babel}
\usepackage[T1]{fontenc}

\usepackage{url}

\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{Definition}{Definition}
\newtheorem*{Definition*}{Definition}
\newtheorem{Example}{Example}
\newtheorem*{Example*}{Example}

\theoremstyle{remark}
\newtheorem*{Remark*}{Remark}

\newtheoremstyle{underline}% name
{}        % Space above, empty = `usual value'
{}              % Space below
{}              % Body font
{}    % Indent amount (empty = no indent, \parindent = para indent)
{}              % Thm head font
{:}             % Punctuation after thm head
{1.5mm}         % Space after thm head: \newline = linebreak
{\underline{\thmname{#1}\thmnumber{ #2}\thmnote{(#3)}}}  % Thm head spec

\theoremstyle{underline}
\newtheorem*{Multiplication*}{Multiplication}

\theoremstyle{underline}
\newtheorem*{Comultiplication*}{Comultiplication}

\DeclareMathOperator{\Mat}{Mat}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}

\setlength{\parindent}{0pt}

\begin{document}

\title{\textbf{Hopf Algebras and Combinatorics}}

\author{\small Vinay Madhusudanan and Arjit Seth \\ \small Manipal Institute of Technology, Manipal University}
\date{}
\maketitle

\renewcommand{\abstractname}{Context}
\begin{abstract}
These are notes created based on the lectures from San Francisco State University under Prof. Federico Ardila. Hopf algebras seem to be a difficult topic to introduce as a simple definition. They apparently have applications in quantum field theory, pertinent to Feynman diagrams.
\end{abstract}

\begingroup
\let\clearpage\relax
\tableofcontents
\endgroup

\medskip
\medskip

\section{Introduction}\label{sec:Intro}
A Hopf algebra is a complicated mathematical structure with a definition involving lots of properties and scary commutative diagrams. It fundamentally invokes the tensor product, and it is difficult to construct as a complete definition in one sitting, so we must do it in pieces.

\begin{Definition}[Hopf algebra]\label{def:HopfAlg}
A \emph{Hopf algebra} $H$ is a $\mathbb{K}$-vector space with five operations:
\begin{center}
	\begin{tabular}{rl}
		Multiplication: &   $ m\colon H \otimes H \to H$\\
		Unit: & $u\colon \mathbb{K} \to H $ \\
		Comultiplication: & 	$ \Delta\colon H \to H \otimes H$\\
		Counit: & $\epsilon\colon H \to \mathbb{K}$ \\
		Antipode: &  $ S\colon H \to H $
	\end{tabular}
\end{center}
\end{Definition}

These definitions invoke lots of commutative diagrams that are difficult to \TeX, so they'll be shown later once a better understanding is developed. Now we must preliminarily define the tensor product.

\begin{Definition}[Tensor product]\label{def:TensorProd}
Let $\mathbb{K}$ be a field, and let $V$ and $W$ be vector spaces over $\mathbb{K}$. The tensor product $ V\otimes W $ is a vector space over $ \mathbb{K} $ generated by vectors $v \otimes w$, $v \in V$, $w \in W$, and satisfying the following properties:
\begin{center}
	Distributivity over addition: \hfill $ (v + v') \otimes (w + w') = v \otimes w + v \otimes w' + v' \otimes w + v' \otimes w'$
	Scalar multiplication independent of two arguments: \hfill $ \lambda(v \otimes w) = \lambda v \otimes w = v \otimes \lambda w$
\end{center}
\end{Definition}

The combination of these is a property called \emph{bilinearity}. Note that this vector space is much larger than the product space $V \times W$:
\begin{align*}
	\dim U \times V & = \dim U + \dim V\\
	\dim U \otimes V & = \dim U \dim V
\end{align*}
This is intuitively obvious because the tensor product defines an \emph{actual} product between elements of $V$ and $W$, instead of a restricted component structure induced by a Cartesian product, which constrains manipulations to $V$ and $W$ independently.

\begin{Example*}[Tensor product of bases]
If $ \qty{v_i}_{i \in I}$ and $ \qty{w_j}_{j \in J} $ are bases of $V$ and $W$, then $ \qty{v_i \otimes w_j \mid i \in I, \; j \in J}$ is a basis for $V \otimes W$. Let $ \qty{v_i}$ and $\qty{w_j} $ be the standard bases in two and three dimensions, represented as column and row vectors respectively. One element of the basis for the tensor product is:
\begin{gather*}
	v_1 \otimes w_3 = \mqty[1 \\ 0] \otimes \mqty[0 & 0 & 1]  = \mqty[0 & 0 & 1 \\ 0 & 0 & 0]
\end{gather*}
It is clear that this construction develops the standard basis for $V_{2} \otimes W_{3}$.
\end{Example*}

\begin{Example*}[Polynomial ring and matrices] 
Let $ V = \mathbb{R}[x]$ and $ W = \Mat_{2\times 2}(\mathbb{R})$. A formal expression of an element in $V \otimes W $ is, for example, $(2 + 2x) \otimes \mqty[0 & 1 \\ 1 & 0]$.
\end{Example*}

\begin{Example*}[Dirac matrices]
The following anticommutation relations have a corresponding matrix representation called the Pauli matrices:
\begin{gather}
	\sigma_i^2 = I_2, \;\; \sigma_i \sigma_j + \sigma_j\sigma_i = 0, \; i \neq j \\
	\sigma_1 = \mqty[0 & 1 \\ 1 & 0],\; \sigma_2 = \mqty[0 & -i \\ i & 0],\; \sigma_3 = \mqty[1 & 0 \\ 0 & -1]
\end{gather}
To develop the relativistic theory of the electron, Dirac constructed $4 \times 4$ matrices $\gamma^\mu,\; \mu = 0,1,2,3$, out of the Pauli matrices using tensor products. The details are not relevant, so we will just display the results:
\begin{gather}
	\gamma \equiv \mqty[0 & 1 \\ -1 & 0] \\
	\gamma^{0} = \sigma_3 \otimes \mathbf 1_2 = \mqty[I_2 & 0 \\ 0 & -I_2] = \mqty[1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & -1 & 0 \\ 0 & 0 & 0 & -1] \\
	\gamma^{i} = \gamma \otimes \sigma_i = \mqty[0 & \sigma_i \\ -\sigma_i & 0],\;\; i = 1,2,3
\end{gather}
The Pauli and Dirac matrices form Clifford algebras respectively, which I don't know anything about.
\end{Example*}

\subsection{Motivating Examples for Hopf Algebras}

\begin{Example}[Groups]
Let $G$ be a \emph{finite group} and $\mathbb{K}$ a \emph{field}. To allow multiplication of scalars into the group, define the group ring:
\begin{gather}
	H = \mathbb KG = \qty{\, \sum_{i = 1}^n\lambda_i g_i \biggm| n \in \mathbb N,\; \forall\,\lambda_i \in \mathbb K,\; \forall\,g_i \in G \,}	
\end{gather}

\begin{Multiplication*}
$m(g \otimes h) = gh$. Extending this linearly:
\begin{gather}
	m(g \otimes h) = \pqty{\sum_{i = 1}^{n}\lambda_i g_i}\pqty{\sum_{j = 1}^{n}\mu_j h_j} = \sum_{i,j}^{n,n} \lambda_i \mu_j(g_i h_j)
\end{gather}
\end{Multiplication*}

\begin{Comultiplication*}
$ \Delta(g) = g \otimes g $. Extending this linearly:
\begin{gather}
	\Delta\pqty{\sum_{i = 1}^n \lambda_ig_i} = \sum_{i = 1}^n \lambda_i(g_i \otimes g_i)
\end{gather}
These definitions do give a Hopf algebra according to the lecturer. 	
\end{Comultiplication*}

\begin{Remark*}
The comultiplication $ \Delta(g) = 1 \otimes g + g \otimes 1 + g \otimes g$ should also be valid, as the mapping \emph{should} point to all possible information of where $g$ can come from. As we will see later, this idea will be partially evident in future definitions of different structures.
\end{Remark*}

\end{Example}


\begin{Example}[Polynomial Rings]
Let $H = \mathbb{K}[X]$, the \emph{polynomial ring}.

\begin{Multiplication*}
$m\pqty{X^i \otimes X^j} = X^{i+j}$. Extending this linearly:
\begin{gather}
	m\pqty{\sum_i^k \alpha_i X^i \otimes \sum_j^l \beta_j X^j} = \sum_{i,j}^{k,l} \alpha_i \beta_j X^{i+j},\;\; \forall\,\alpha_i,\beta_j \in \mathbb K,\; \forall\,	k,l \in \mathbb N
\end{gather}
\end{Multiplication*}

\begin{Remark*}
This is a commutative multiplication because the ring forms a commutative algebra by definition, making the multiplication of the tensor product commutative in $i$ and $j$. This linear extension is obvious because the ring is commutative in addition by definition.
\end{Remark*}

\begin{Comultiplication*}
Extending the logic from groups:
\begin{gather}
	\Delta\pqty{X} = \pqty{1 \otimes X} + \pqty{X \otimes 1}
\end{gather}
\end{Comultiplication*}

\begin{Remark*}
The combination $\pqty{X \otimes X}$ is not included here probably because the addition of ring elements is analogous to multiplication of group elements, justifying $g \otimes g$ in the definition for groups. \\
\end{Remark*}

This ring already has a multiplicative structure, which the coproduct should obey naturally:
\begin{gather}
	\Delta\pqty{X^2} = \bqty{1 \otimes X + X \otimes 1} \cdot \bqty{1 \otimes X + X \otimes 1} \\
	= 1 \otimes X^2 + 2\pqty{X\otimes X} + X^2 \otimes 1 
\end{gather}
This suggests the following extension:
\begin{gather}
	\Delta\pqty{X^{n}} = \sum_{i}^{n} \binom{n}{i}\pqty{X^{i} \otimes X^{n-i}} 
\end{gather}
Notice the following, which shows the information about the coefficient of a comultiplication:
\begin{gather}
	m\pqty{\Delta\pqty{X^n}} = \sum_{i}^{n} \binom{n}{i}X^n =  2^nX^n
\end{gather}

\end{Example}

\begin{Example}[Graphs]
Let $[G]$ be the \emph{isomorphism class of the graph} $G = (V,E)$. The class of all isomorphic graphs is denoted by $L = \qty{\, [G] \mid \; G \in \cal G \,}$, where $\cal G$ is the class of all graphs. Let the vector space $H = \mathbb KL$, in which the elements are linear combinations of graphs:
\begin{gather}
	H = \qty{\, \sum_i k_i[G_i]\,\bigg|\;k \in \mathbb K,\; G \in \cal G\,}	
\end{gather}

\begin{Multiplication*}
Defined most naturally as a disjoint union of the arguments as components of the graph, which is commutative:
\begin{equation}
	m\mqty(\;
	\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		\node (n1) at (1,0)	{};
		\node (n2) at (1.5,1)	{};
		\node (n3) at (2,0)	{};
		\foreach \from/\to in {n3/n2, n2/n1}
	    \draw (\from) -- (\to);
	}}\,
	\otimes\,
	\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		[scale=1,auto=left,every node/.style={circle,fill=gray}]
		\node (n4) at (5,1)	{};
	  	\node (n5) at (5,0)	{};
	  	\node (n6) at (6,1)	{};
	  	\node (n7) at (6,0)	{};
	  	\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
	  	\draw (\from) -- (\to);
	}}\;)
	= \mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		\node (n1) at (1,0)	{};
		\node (n2) at (1.5,1)	{};
		\node (n3) at (2,0)	{};
		\foreach \from/\to in {n3/n2, n2/n1}
	    \draw (\from) -- (\to);
	}&
	\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		[scale=1,auto=left,every node/.style={circle,fill=gray}]
		\node (n4) at (5,1)	{};
	  	\node (n5) at (5,0)	{};
	  	\node (n6) at (6,1)	{};
	  	\node (n7) at (6,0)	{};
	  	\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
	  	\draw (\from) -- (\to);
	}}
\end{equation}
\end{Multiplication*}

\begin{Comultiplication*}
Not entirely obvious, but a satisfactory definition can be deduced from the previous examples and observations. The comultiplication structure of an element is essentially a decomposition of the components by taking complementary combinations of the subelements of the algebraic structure (FIX THIS). \\
This idea can be implemented in this vector space as well by selecting a subset $S$ of the vertex set of the graph $V(G)$, constructing the graph based on the existence of edges between the vertices of $S$, and taking a tensor product with its complement. This is shown by (dropping the isomorphism class notation for brevity):
\begin{gather}
	\Delta(G) = \sum_{S \in V(G)} G\big|_S \otimes G\big|_{V(G) - S}
\end{gather}
This is illustrated using the following example:
\begin{gather}
	\Delta
	\mqty(\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		\node (n4) at (5,0.6)	{};
		\node (n5) at (5,0)	{};
		\node (n6) at (6,0.6)	{};
		\node (n7) at (6,0)	{};
		\node (n8) at (5.5,1) {};
	  	\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7, n4/n8, n6/n8}
	  	\draw (\from) -- (\to);
	}) = 
	\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		\node (n4) at (5,0.5)	{};
	  	\node (n5) at (5,0)	{};
	  	\node (n6) at (5.3,1) {};
	  	\foreach \from/\to in {n4/n5, n4/n6}
	  	\draw (\from) -- (\to);
	}}\otimes \;
	\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		\node (n4) at (5,1)	{};
	  	\node (n5) at (5,0.3)	{};
	  	\foreach \from/\to in {n4/n5}
	  	\draw (\from) -- (\to);
	}}) + 
	\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		[scale=1,auto=left,every node/.style={circle,fill=gray}]
		\node (n4) at (5,1)	{};
	  	\node (n5) at (5,0)	{};
	  	\node (n6) at (6,1)	{};
	  	\node (n7) at (6,0)	{};
	  	\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
	  	\draw (\from) -- (\to);
	}} \otimes\;
	\mqty{\tikz[scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		[scale=1,auto=left,every node/.style={circle,fill=gray}]
		\node (n4) at (5,0)	{};
	}})\; + 
	\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		[scale=1,auto=left,every node/.style={circle,fill=gray}]
	  	\node (n5) at (5,0)	{};
	  	\node (n6) at (5.5,0.5)	{};
	  	\foreach \from/\to in {n5/n6}
	  	\draw (\from) -- (\to);
	}}\, \otimes
	\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=gray,inner sep=0pt,minimum size=2mm}]
	{
		[scale=1,auto=left,every node/.style={circle,fill=gray}]
	  	\node (n5) at (5,0)	{};
	  	\node (n6) at (6,1)	{};
	  	\node (n7) at (6,0)	{};
	  	\foreach \from/\to in {n5/n6, n5/n7, n6/n7}
	  	\draw (\from) -- (\to);
	}}) +
	\ldots
\end{gather}
The number of tensor products is easily countable as the number of subsets of $V(G)$, which is $2^n$, where $n$ is the number of vertices of the graph $G$. For the above example, there are 5 vertices, so there are 32 tensor products to be summed over.
\end{Comultiplication*}

\begin{Remark*}
The product of the coproduct of a graph is:
\begin{gather}
	m\pqty{\Delta(G)} \neq G
\end{gather}
This indicates that the product of the coproduct of a graph does not bring back the original argument, so $m$ and $\Delta$ are not inverse operations. (Note: This is also evident from the group and the polynomial ring examples.)
\end{Remark*}

\end{Example}

\begin{Example}[Permutations]
Let $P_n$ denote the set of \emph{all permutations of the subsets} of $\mathbb N\Mod n$, where $n$ is finite. To clarify with an example, take the set $\mathbb N\Mod 5 = \qty{\, 1,2,3,4,5 \,}$. Here are two permutations of $P_5$:
\begin{gather}
	p = \mqty(1 & 2 & 3 & 4 & 5 \\ 2 & 1 & 3 & 4 & 5), \;\; q = \mqty(1 & 2 \\ 2 & 1) 
\end{gather}

\begin{Remark*}
Although they might have the `same' action, they are fundamentally different elements (of $S_5$ and $S_2$, respectively in the above example) by definition. The set $P_n$ consists of elements of the permutation groups $S_1$ to $S_n$. (CHECK)
\end{Remark*}

The vector space is defined as:
\begin{gather}
	H = \mathbb KP_n = \qty{\, \sum_{i}^n k_iP_i \;\bigg|\; \forall\, k_i \in \mathbb K,\;\forall\, P_i \in P_n,\;\forall\,n \in \mathbb N\,}
\end{gather}
Note that the coefficients do not imply the number of times of application of their corresponding permutations; they just depict a formal linear extension for the vector space.

\begin{Multiplication*}
An example is $(1 \, 2) \otimes (1 \, 2 \,3)$ using one-line notation:
\begin{gather}
	m((1 \, 2) \otimes (3 \, 2 \, 1)) = 12543 + 15243 + 15423 + 15432 + 51243 + 51423 + \ldots 
\end{gather}
Which shows that it respects the order of the arguments while shuffling and generates only \emph{some} permutations of $S_5$ as a result. This might be represented by using $U_i$ to denote the $i$th entry of the permutation $U$:
\begin{gather}
	m\pqty{U \otimes V} = m\pqty{\pqty{U_1\ldots U_j} \otimes \pqty{V_1\ldots V_k}} \\
	= \sum p(U_1\ldots V_{j + 1} \ldots U_j\ldots V_{j + k}),\;\; n(U_j) < n(U_{j+1}), \; n(V_{i + j}) < n(V_{i + j + 1}) 
\end{gather}
Where $p(U_1\ldots V_{i + 1} \ldots U_i\ldots V_{i + j})$ stands for the permutations of the resultant set with the values of $V_i$ right-shifted by $j$, under the rule that the partial order of the elements is not lost, using $n(U_i)$ to denote placement. (NEEDS IMPROVEMENT)
\end{Multiplication*}

\begin{Comultiplication*}
Similar to graphs, the coproduct of permutations is obtained by cutting a line between the numbers (in one-line notation, e.g. $(1 \, 2 \mid 3\, 4\, 5)$), and writing the outer product with each piece as a component, then summing over all complementary combinations. 
\begin{gather}
	\Delta\pqty{U_1 U_2 \ldots U_n} = \sum_{i=0}^n \pqty{U_1\ldots U_i} \otimes \pqty{U_{i+1}\ldots U_n}
\end{gather}
An example using a permutation of $S_5$:
\begin{gather}
	\Delta\pqty{4 \, 2 \, 5 \, 3 \, 1} = \pqty{\phi \otimes 42531} + \pqty{1 \otimes 2431} + \pqty{21 \otimes 321} + \ldots
\end{gather}
\emph{Note}: Substrings like $(4 \, 5 \, 3)$ are just elements of $S_3$, so they can be rewritten as $(2 \, 3 \, 1)$, and so on for substrings of varying lengths with their corresponding symmetric groups. 
\end{Comultiplication*}

\begin{Remark*}
Nothing so far.
\end{Remark*}
\end{Example}

\section{Algebras Over a Field}
\end{document}