% Hopf Algebras and Combinatorics

\documentclass[svgnames]{article}
\usepackage[paperwidth=6in, paperheight=8in, top = 20mm, bottom = 18mm, left=10mm, right = 10mm]{geometry}

\usepackage{natbib}

\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage[all, cmtip, 2cell]{xy}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{physics}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{enumitem}

\usepackage{tocloft}
\renewcommand{\cftdot}{}

\usepackage{hyperref}
\hypersetup{colorlinks, linkcolor = [RGB]{66, 128, 128}, urlcolor = red, linktocpage = true}


\usepackage{newpxmath}
\usepackage{charter}
\usepackage[T1]{fontenc}


\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{Definition}{Definition}
\newtheorem*{Definition*}{Definition}
\newtheorem{Example}{Example}
\newtheorem*{Example*}{Example}
\newtheorem{Exercise}{Exercise}

\theoremstyle{remark}
\newtheorem*{Remark*}{Remark}
\newtheorem*{Solution*}{Solution}
\newtheorem*{Note*}{Note}


\newtheoremstyle{underline}% name
{}        % Space above, empty = `usual value'
{}              % Space below
{}              % Body font
{}    % Indent amount (empty = no indent, \parindent = para indent)
{}              % Thm head font
{:}             % Punctuation after thm head
{1.5mm}         % Space after thm head: \newline = linebreak
{\underline{\thmname{#1}\thmnumber{ #2}\thmnote{(#3)}}}  % Thm head spec

\theoremstyle{underline}
\newtheorem*{Multiplication*}{Multiplication}

\theoremstyle{underline}
\newtheorem*{Comultiplication*}{Comultiplication}

\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\Hilb}{Hilb}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}

\let\Im\relax
\DeclareMathOperator{\Im}{Im}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\Iso}{\mathrm{Iso}}
\renewcommand{\th}{\textsuperscript{th}\xspace}

\newlist{subquests}{enumerate}{2}
\setlist[subquests, 1]{label = (\alph*)}
\setlist[subquests, 2]{label = \roman*.}

\setlength{\parindent}{0pt}


\begin{document}
	
	\title{\textbf{Hopf Algebras and Combinatorics}}
	
	\author{\small Arjit Seth and M. Vinay \\ \small Manipal Institute of Technology, Manipal University}
	\date{}
	\maketitle
	
	\renewcommand{\abstractname}{Context}
	\begin{abstract}
		These are notes created based on the lectures by Prof. Federico Ardila at San Francisco State University. Hopf algebras seem to be a difficult topic to introduce as a simple definition. They apparently have applications in quantum field theory, pertinent to Feynman diagrams and renormalisation.
	\end{abstract}
	
	\begingroup
	\let\clearpage\relax
	\tableofcontents
	\endgroup
	
	\newpage
	
	\section{Introduction}\label{sec:Intro}
	A Hopf algebra is a complicated mathematical structure with a definition involving lots of properties and scary commutative diagrams. It fundamentally invokes the tensor product and develops coalgebras with their respective properties, which merits thorough investigation. Some interesting examples allow for good practice in combinatorics as well so far. It is difficult to construct as a complete definition in one sitting, so we must start with smaller definitions and build up the structure progressively.
	
	\begin{Definition}[Hopf algebra]\label{def:HopfAlg}
		A \emph{Hopf algebra} $H$ is a $\mathbb{K}$-vector space with five operations:
		\begin{center}
			\begin{tabular}{rl}
				Multiplication: &   $ m \colon H \otimes H \to H$\\
				Unit: & $u \colon \mathbb{K} \to H $ \\
				Comultiplication: & 	$ \Delta \colon H \to H \otimes H$\\
				Counit: & $\epsilon \colon H \to \mathbb{K}$ \\
				Antipode: &  $ S \colon H \to H $
			\end{tabular}
		\end{center}
	\end{Definition}
	
	These definitions invoke lots of commutative diagrams that are difficult to \TeX, so they'll be shown later once a better understanding is developed. Now we must preliminarily define the tensor product.
	
	\begin{Definition}[Tensor product]\label{def:TensorProd}
		Let $\mathbb{K}$ be a field, and let $V$ and $W$ be vector spaces over $\mathbb{K}$. The tensor product $ V\otimes W $ is a vector space over $ \mathbb{K} $ generated by vectors $v \otimes w$, $v \in V$, $w \in W$, and satisfying the following properties:
		\begin{center}
			Distributivity over addition: \hfill $ (v + v') \otimes (w + w') = v \otimes w + v \otimes w' + v' \otimes w + v' \otimes w'$\\
			Scalar multiplication independent of two arguments: \hfill $ \lambda(v \otimes w) = \lambda v \otimes w = v \otimes \lambda w$
		\end{center}
	\end{Definition}
	
	The combination of these is a property called \emph{bilinearity}. Note that this vector space is much larger than the product space $V \times W$:
	\begin{align*}
		\dim U \times V & = \dim U + \dim V\\
		\dim U \otimes V & = \dim U \dim V
	\end{align*}
	This is intuitively obvious because the tensor product defines an \emph{actual} product between elements of $V$ and $W$, instead of a restricted component structure induced by a Cartesian product, which constrains manipulations to $V$ and $W$ independently.
	
	\begin{Example*}[Tensor product of bases]
		If $ \qty{v_i}_{i \in I}$ and $ \qty{w_j}_{j \in J} $ are bases of $V$ and $W$, then $ \qty{v_i \otimes w_j \mid i \in I, \; j \in J}$ is a basis for $V \otimes W$. Let $ \qty{v_i}$ and $\qty{w_j} $ be the standard bases in two and three dimensions, represented as column and row vectors respectively. One element of the basis for the tensor product is:
		\begin{gather*}
		v_1 \otimes w_3 = \mqty[1 \\ 0] \otimes \mqty[0 & 0 & 1]  = \mqty[0 & 0 & 1 \\ 0 & 0 & 0]
		\end{gather*}
		It is clear that this construction develops the standard basis for $V_{2} \otimes W_{3}$.
	\end{Example*}
	
	\begin{Example*}[Polynomial ring and matrices] 
		Let $ V = \mathbb{R}[x]$ and $ W = \Mat_{2\times 2}(\mathbb{R})$. A formal expression of an element in $V \otimes W $ is, for example, $(2 + 2x) \otimes \mqty[0 & 1 \\ 1 & 0]$.
	\end{Example*}
	
	\begin{Example*}[Dirac matrices]
		The following anticommutation relations have a corresponding matrix representation called the Pauli matrices:
		\begin{gather*}
		\sigma_i^2 = I_2, \quad \sigma_i \sigma_j + \sigma_j\sigma_i = 0, \; i \neq j \\
		\sigma_1 = \mqty[0 & 1 \\ 1 & 0],\; \sigma_2 = \mqty[0 & -i \\ i & 0],\; \sigma_3 = \mqty[1 & 0 \\ 0 & -1]
		\end{gather*}
		To develop the relativistic theory of the electron, Dirac constructed $4 \times 4$ matrices $\gamma^\mu,\; \mu = 0,1,2,3$, out of the Pauli matrices using tensor products. The details are not relevant, so we will just display the results:
		\begin{gather*}
		\gamma \coloneqq \mqty[0 & 1 \\ -1 & 0] \\
		\gamma^{0} = \sigma_3 \otimes I_2 = \mqty[I_2 & 0 \\ 0 & -I_2] = \mqty[1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & -1 & 0 \\ 0 & 0 & 0 & -1] \\
		\gamma^{i} = \gamma \otimes \sigma_i = \mqty[0 & \sigma_i \\ -\sigma_i & 0],\quad i = 1,2,3
		\end{gather*}
		The Pauli and Dirac matrices form Clifford algebras respectively.
	\end{Example*}
	
	\subsection{Motivating Examples for Hopf Algebras}
	
	\begin{Example}[Groups]
		Let $G$ be a \emph{finite group} and $\mathbb{K}$ a \emph{field}. To allow multiplication of scalars into the group, define the group ring:
		\begin{gather*}
		H = \mathbb KG = \qty{\, \sum_{i = 1}^n\lambda_i g_i \biggm| n \in \mathbb N,\; \lambda_i \in \mathbb K,\; g_i \in G \,}	
		\end{gather*}
		with the ring multiplication	$g \cdot h= gh$, the group multiplication. Extending this linearly:
			\begin{gather*}
			\pqty{\sum_{i = 1}^{m}\lambda_i g_i}\pqty{\sum_{j = 1}^{n}\mu_j h_j} = \sum_{i = 1}^m \sum_{j = 1}^n \lambda_i \mu_j(g_i h_j)
			\end{gather*}
		
		\begin{Comultiplication*}
			$ \Delta(g) = g \otimes g $. Extending this linearly:
			\begin{gather*}
				\Delta\pqty{\sum_{i = 1}^n \lambda_ig_i} = \sum_{i = 1}^n \lambda_i(g_i \otimes g_i)
			\end{gather*}
			These definitions do give a Hopf algebra according to the lecturer. 	
		\end{Comultiplication*}
		
		\begin{Remark*}
			The comultiplication $ \Delta(g) = 1 \otimes g + g \otimes 1 + g \otimes g$ should also be valid, as the mapping \emph{should} point to all possible information of where $g$ can come from. As we will see later, this idea will be partially evident in future definitions of different structures.
		\end{Remark*}
		
	\end{Example}
	
	
	\begin{Example}[Polynomial rings]
		Let $H = \mathbb{K}[X]$, the \emph{polynomial ring}.
		
		\begin{Multiplication*}
			$m\pqty{X^i \otimes X^j} = X^{i+j}$. Extending this linearly:
			\begin{gather*}
			m\pqty{\sum_{i = 0}^n \alpha_i X^i \otimes \sum_{j = 0}^p \beta_j X^j} = \sum_{i = 0}^n \sum_{j = 0}^p \alpha_i \beta_j X^{i+j}, \quad \forall\,\alpha_i,\beta_j \in \mathbb K,\; \forall\,	n, p\in \mathbb N
			\end{gather*}
		\end{Multiplication*}
		
		\begin{Remark*}
			This is a commutative multiplication because $X^{i + j} = X^{j + i}$.
		\end{Remark*}
		
		\begin{Comultiplication*}
			Extending the logic from groups:
			\begin{gather*}
			\Delta\pqty{X} = \pqty{1 \otimes X} + \pqty{X \otimes 1}
			\end{gather*}
		\end{Comultiplication*}
		
		\begin{Remark*}
			The combination $\pqty{X \otimes X}$ is not included here probably because the addition of ring elements is analogous to multiplication of group elements, justifying $g \otimes g$ in the definition for groups. \\
		\end{Remark*}
		
		This ring already has a multiplicative structure, which the coproduct should obey naturally:
		\begin{gather*}
		\Delta\pqty{X^2} = \bqty{1 \otimes X + X \otimes 1} \cdot \bqty{1 \otimes X + X \otimes 1} \\
		= 1 \otimes X^2 + 2\pqty{X\otimes X} + X^2 \otimes 1 
		\end{gather*}
		This suggests the following extension:
		\begin{gather*}
		\Delta\pqty{X^{n}} = \sum_{i=1}^{n} \binom{n}{i}\pqty{X^{i} \otimes X^{n-i}} 
		\end{gather*}
		Notice the following, which shows the information about the coefficient of a comultiplication:
		\begin{gather*}
		m\pqty{\Delta\pqty{X^n}} = \sum_{i=1}^{n} \binom{n}{i}X^n =  2^nX^n
		\end{gather*}
		
	\end{Example}
	
	\begin{Example}[Graphs]
		Let $[G]$ be the \emph{isomorphism class of the graph} $G = (V,E)$. The collection of all isomorphic graphs is denoted by $L = \qty{\, [G] \mid \; G \in \mathcal G \,}$, where $\mathcal G$ is the class of all graphs. Define the vector space $H = \mathbb KL$, in which the elements are linear combinations of graphs:
		\begin{gather*}
		H = \qty{\, \sum_{i = 1}^n k_i[G_i]\,\bigg|\;k_i \in \mathbb K,\; G_i \in \mathcal G,\; n \in \mathbb N_0 \,}	
		\end{gather*}
		
		\begin{Multiplication*}
			Defined most naturally as a disjoint union of the arguments as components of the graph, which is commutative:
			\begin{equation}
			m\mqty(\;
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					\node (n1) at (1,0)	{};
					\node (n2) at (1.5,1)	{};
					\node (n3) at (2,0)	{};
					\foreach \from/\to in {n3/n2, n2/n1}
					\draw (\from) -- (\to);
			}}\,
			\otimes\,
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=black}]
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}}\;)
			= \mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					\node (n1) at (1,0)	{};
					\node (n2) at (1.5,1)	{};
					\node (n3) at (2,0)	{};
					\foreach \from/\to in {n3/n2, n2/n1}
					\draw (\from) -- (\to);
				}&
				\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=gray}]
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}}
			\end{equation}
		\end{Multiplication*}
		
		\begin{Comultiplication*}
			Not entirely obvious, but a satisfactory definition can be deduced from the previous examples and observations. The comultiplication of an element is essentially the sum of all of its possible decompositions into two complementary subelements.\\
			This idea can be implemented in this algebra as well by selecting a subset $S$ of the vertex set of the graph $V(G)$ and taking the tensor product of the graphs induced by $S$ and its complement $V(G) - S$ (a graph induced by a subset of the vertex set consists of vertices in that subset and all of the edges between these vertices that occur in the original graph). This is shown by (dropping the isomorphism class notation for brevity):
			\begin{gather*}
			\Delta(G) = \sum_{S \subseteq V(G)} G\big|_S \otimes G\big|_{V(G) - S}
			\end{gather*}
			This is illustrated using the following example:
			\begin{gather*}
			\Delta
			\mqty(\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
			{
				\node (n4) at (5,0.6)	{};
				\node (n5) at (5,0)	{};
				\node (n6) at (6,0.6)	{};
				\node (n7) at (6,0)	{};
				\node (n8) at (5.5,1) {};
				\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7, n4/n8, n6/n8}
				\draw (\from) -- (\to);
			}) = 
			\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					\node (n4) at (5,0.5)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (5.3,1) {};
					\foreach \from/\to in {n4/n5, n4/n6}
					\draw (\from) -- (\to);
			}}\otimes \;
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0.3)	{};
					\foreach \from/\to in {n4/n5}
					\draw (\from) -- (\to);
			}}) + 
			\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=black}]
					\node (n4) at (5,1)	{};
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n4/n5, n4/n6, n4/n7, n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}} \otimes\;
			\mqty{\tikz[scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=black}]
					\node (n4) at (5,0)	{};
			}})\; + 
			\mqty(\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=black}]
					\node (n5) at (5,0)	{};
					\node (n6) at (5.5,0.5)	{};
					\foreach \from/\to in {n5/n6}
					\draw (\from) -- (\to);
			}}\, \otimes
			\mqty{\tikz[baseline=(current bounding box.center),scale=1,auto=left,every node/.style={circle,fill=black,inner sep=0pt,minimum size=1.8mm}]
				{
					[scale=1,auto=left,every node/.style={circle,fill=black}]
					\node (n5) at (5,0)	{};
					\node (n6) at (6,1)	{};
					\node (n7) at (6,0)	{};
					\foreach \from/\to in {n5/n6, n5/n7, n6/n7}
					\draw (\from) -- (\to);
			}}) +
			\cdots
			\end{gather*}
			The number of tensor products is easily countable as the number of subsets of $V(G)$, which is $2^n$, where $n$ is the number of vertices of the graph $G$. For the above example, there are 5 vertices, so there are 32 tensor products to be summed over.
		\end{Comultiplication*}
		
		\begin{Remark*}
			The product of the coproduct of a graph is:
			\begin{gather*}
			m\pqty{\Delta(G)} \neq G
			\end{gather*}
			This indicates that the product of the coproduct of a graph does not bring back the original argument, so $m$ and $\Delta$ are not inverse operations. (Note: This is also evident from the group and the polynomial ring examples.)
		\end{Remark*}
		
	\end{Example}
	
	\begin{Example}[Permutations]
		Let $P_n$ denote the set of all permutations of $\mathbb N\Mod n \coloneqq \qty{1, 2, \ldots, n}$, for a given non-negative integer $n$. Let $P$ denote the set of all permutations of $\mathbb N \Mod n$, for all non-negative integers $n$ --- i.e., $P \coloneqq \bigcup\limits_{n = 0}^\infty P_n$. Here are two permutations in $P$:
		\begin{gather*}
		p = \mqty(1 & 2 & 3 & 4 & 5 \\ 2 & 1 & 3 & 4 & 5), \;\; q = \mqty(1 & 2 \\ 2 & 1) 
		\end{gather*}
		
		\begin{Remark*}
			Although they might have the `same' action, they are fundamentally different elements of $P$, as $p$ is an element of $P_5$ and $q$ that of $P_2$.
		\end{Remark*}
		
		The vector space is defined as:
		\begin{gather*}
		H = \mathbb KP \coloneqq \qty{\, \sum_{i = 1}^n k_i p_i \;\bigg|\; k_i \in \mathbb K,\; p_i \in P,\; n \in \mathbb N_0\,}
		\end{gather*}
		Note that the coefficients do \emph{not} denote the number of times of application of their corresponding permutations; they just depict a formal linear extension in the vector space.
		
		\begin{Multiplication*}
			An example is $12 \otimes 321$ using one-line notation:
			\begin{align*}
			m(12 \otimes 321) = & 12543 + 15243 + 15423 + 15432 + 51243 + {}\\
				& 51423 +  51432 + 54123 + 54132 + 54312
			\end{align*}
			This shows that it respects the relative order of the elements within each argument as in a riffle shuffle of cards and generates only \emph{some} permutations in $P_5$ as a result. Also note how the elements $1, 2, 3$ in the second argument were relabelled $3, 4, 5$ respectively, to ensure that we get an element of $P_5$ after shuffling. This might be represented as given below, with $u_i$ denoting the $i$\th element in the permutation $U$:
			\begin{gather*}
			m\pqty{U \otimes V} = m\pqty{u_1 \cdots u_n \otimes v_1 \cdots v_p} \\
			= \sum w_1 \cdots w_{n + p}
			\end{gather*}
			Where $w_1 \cdots w_{n + p}$ stands for every possible permutation of the resultant set with the values of $v_j$ right-shifted by $n$, under the rule that the relative orders of the elements of $U$ and $V$ respectively are not lost --- i.e., for any two $w_i$, $w_j$, $1 \le i < j \le n + p$, one of the following holds:
			\begin{enumerate}
				\item $w_i = u_k$ and $w_j = v_r + n$ 
				\item $w_i = v_r + n$ and $w_j = u_k$
				\item $w_i = u_k$ and $w_j = u_l$, with $k < l$
				\item $w_i = v_r + n$ and $w_j = v_s + n$, with $r < s$
			\end{enumerate}
			where $1 \le k, l \le n$, $1 \le r, s \le p$.
		\end{Multiplication*}
		
		\begin{Comultiplication*}
			Similar to graphs, the coproduct of permutations is obtained by cutting a line between the numbers (in one-line notation, e.g. $12 \mid 345$), and writing the outer product with each piece as a component, then summing over all complementary combinations. 
			\begin{gather*}
			\Delta\pqty{u_1 u_2 \cdots u_n} = \sum_{i=0}^n u_1 \cdots u_i \otimes v_1 \cdots v_{n - i}
			\end{gather*}
			where $v_1, \ldots, v_{n - i}$ are obtained by relabelling $u_{i + 1}, \ldots, u_n$ respectively in such a way that the resulting set $\qty{v_1, \ldots, v_{n - i}} = \mathbb N \Mod {(n - i)}$, but preserving the relative order of elements. An example using a permutation of $P_5$:
			\begin{gather*}
			\Delta\pqty{42531} = \pqty{\varnothing \otimes 42531} + \pqty{1 \otimes 2431} + \pqty{21 \otimes 321} + \cdots
			\end{gather*}
		\end{Comultiplication*}
		
		\begin{Remark*}
			Nothing so far.
		\end{Remark*}
	\end{Example}
	
	\section{Algebras Over a Field/Ring}
	
	An \emph{algebra over a field} is a structure that is simultaneously a \emph{vector space} and a \emph{ring}. The setup will be a field $\mathbb K$ and a ring $A$ with a multiplicative identity $1$, called a $\mathbb K$-algebra.
	Three definitions are introduced that will be shown to be equivalent.
	
	\begin{Definition}[$\mathbb K$-algebra]\label{def:k-Alg-1}
		$A$ forms a $\mathbb K$\emph{-algebra} if $\mathbb K \subseteq Z(A)$ and $1_{\mathbb K} = 1_A$, where $Z(A)$ is the centre of the ring.
	\end{Definition}
	
	\begin{Example*}[Polynomial rings]
		Let $A = \mathbb K[x]$. This forms a $\mathbb K$-algebra because the ring is commutative and the elements of the field in the ring are the constant polynomials, and $1_{\mathbb K}$ is the same as $1_A$. This directly generalises to the multivariate polynomial ring $B = \mathbb K[x_1,\ldots,x_n]$, $n \in \mathbb N$.
	\end{Example*}
	
	An example of a ring that is a vector space, but does not form a $\mathbb K$-algebra as per Definition~\ref{def:k-Alg-1} is $A = \Mat_{n\times n}(\mathbb K)$. This is because $\mathbb K \not\subseteq A$. However, a ``copy'' of $\mathbb K$ exists as the subfield of matrices of the form $\lambda I$, where $I$ is the identity matrix of corresponding dimensions, and $\lambda \in \mathbb K$. This structure should form a $\mathbb K$-algebra, which motivates the second definition.
	
	\begin{Definition}[$\mathbb K$-algebra]
		$A$ is a $\mathbb K$\emph{-algebra} if there is an embedding $u \colon \mathbb K \to A$ such that $u(\mathbb K) \subseteq Z(A)$ and $u\pqty{1_{\mathbb K}} = 1_A $.
	\end{Definition}
	
	\begin{Remark*}
		This allows $A = \Mat_{n\times n}(\mathbb K)$ to form a $\mathbb K$-algebra if we define $u(\lambda) = \lambda I,\, \forall \lambda \in \mathbb K$. An observation is that any $A$ now forms a $\mathbb K$-vector space because scalar multiplication is implemented as $\lambda \cdot a \coloneqq u(\lambda)a,\, \lambda \in \mathbb K,\, a \in A$. The construction of the polynomial ring $\mathbb K[x]$ as a $\mathbb K$-algebra also follows directly from this definition.
	\end{Remark*}
	
	An \emph{algebra over a ring}, by analogy, is a module and a ring with a multiplicative identity defined similarly:
	
	\begin{Definition}[$R$-algebra]
		$M$ is an $R$\emph{-algebra} if there is a ring homomorphism $u \colon R \to M$ such that $u(R) \subseteq Z(A)$ and $u\pqty{1_{R}} = 1_A $ with a left or right multiplication specified.
	\end{Definition}
	
	\begin{Example*}[$\mathbb Z$-algebra]
		A quaternion $a + bi + cj + dk$ is a \emph{Hurwitz quaternion} if $a$, $b$, $c$, and $d$ are either all integers, or all half-integers --- i.e., halves of odd integers. Let
		\begin{gather*}
		H \coloneqq \qty{\, a + bi + cj + dk \,\bigg|\, a, b, c, d \in \mathbb Z\ \text{or}\ a, b, c, d \in \mathbb Z + \frac 1 2 \,}
		\end{gather*}
		be the set of all Hurwitz quaternions. Then $H$ is a $\mathbb Z$-algebra, since its centre consists of all Hurwitz quaternions with imaginary parts zero, which contains a copy of $\mathbb Z$ as a subring.
	\end{Example*}
	
	\subsection{Algebra Homomorphism}
	
	\begin{Definition}\label{def:alghom}
		Let $A_1, A_2$ be $\mathbb K$-algebras. An \emph{algebra homomorphism} is $\phi \colon A_1 \to A_2$ which is a ring homomorphism and linear map simultaneously. 
	\end{Definition}
	
	\begin{Remark*}
		Observations:
		\begin{itemize}
			\item $ B \subseteq A $ is a subalgebra if $B$ is both a subspace and subring. 
			\item A structure that quotients the algebra must quotient the vector space and the ring simultaneously. A subspace quotients the vector space, and an ideal quotients the ring. All ideals form subspaces, therefore ideals quotient the algebra. 
			\item If $\phi \colon A \to B $ is a $\mathbb K$-algebra homomorphism, then $\Im \phi \cong A/\ker \phi$, where $\ker\phi$ forms an ideal $I$. This is analogous to the first isomorphism theorem for groups, rings, vector spaces, etc.
			\item The direct product of two $\mathbb K$-algebras is also a $\mathbb K$-algebra, as the vector space and ring structures are independently inherited. The tensor product also forms a $\mathbb K$-algebra.
		\end{itemize}
	\end{Remark*}
	
	\begin{Definition}[$\mathbb K$-algebra]
		A $\mathbb K$-algebra is a vector space $A$ over a field $\mathbb K$ equipped with linear maps 
		\begin{center}
			\begin{tabular}{rl}
		 		Multiplication: & $m \colon C \otimes C \rightarrow C$ \\
		 		Unit: & $ u \colon C \rightarrow \mathbb K$ 
			\end{tabular}
		\end{center} such that the following diagrams commute:
		\begin{align*}
		\xymatrix{
			A \otimes A \otimes A \ar[d]_-{\id \otimes m} \ar[r]^-{m \otimes \id} & A \otimes A \ar[d]^-{m} \\
			A \otimes A \ar[r]_-{m} & A
		} & &
		\xymatrix{
			\mathbb K \otimes A \ar[r]^-{u \otimes \id} \ar[dr]_-{f} & A \otimes A \ar[d]_-{m} & A \otimes \mathbb K \ar[l]_-{\id \otimes u} \ar[dl]^-{g} \\
			& A &	
		}
		\end{align*}
		where $f$ and $g$ are the natural isomorphisms $\mathbb K \otimes A \to A$, $\lambda \otimes x \mapsto \lambda x$ and $A \otimes \mathbb K \to A$, $x \otimes \lambda \mapsto \lambda x$ respectively.
	\end{Definition}
	
	\begin{Remark*} For vectors $x$ and $y$, we write $m(x, y)$ as $xy$.\\
		For the first diagram: $(m \otimes \id)(x \otimes y \otimes z) = xy \otimes z,\; m(xy \otimes z) = (xy)z $ and $(\id \otimes m)(x \otimes y \otimes z) = x \otimes y z,\; m(x \otimes yz) = x(yz)$, which shows that the multiplication $m$ is \emph{associative}:
		\begin{gather*}
		m(m(x \otimes y) \otimes z) = m(x \otimes m(y \otimes z))
		\end{gather*}
		
		For the second diagram: $(u \otimes \id) (\lambda \otimes x) = u(\lambda) \otimes x$, and $m(u(\lambda) \otimes x) = u(\lambda) x$; also, $f(\lambda \otimes x) = \lambda x$. Since the diagram commutes, $u(\lambda) x = \lambda x$. This shows that left-multiplying a vector $x$ by the vector $u(\lambda)$ is equivalent to multiplying it by the scalar $\lambda$. The same holds for right multiplication. If $1_A \coloneqq u(1_{\mathbb K})$, then $1_A x = 1_{\mathbb K} x = x$ and $x 1_A = x 1_{\mathbb K} = x$, which shows that the multiplication $m$ is \emph{unitary}, with unity $1_A$.
		
		This definition is equivalent to the previous one, which can be verified by checking if the structure shares the remaining property of a ring, \emph{distributivity}, which is satisfied because of the linearity of $m$:
		\begin{gather*}
		m(u \otimes (v + w)) = m(u \otimes v) + m(u \otimes w) = uv + uw
		\end{gather*}
	\end{Remark*}
	
	\begin{Remark*}
		To show that the previous definition implies the current one, the only non-trivial construction required is $m$, which is defined as a multiplication under the previous definition: $m \colon A \otimes A \rightarrow A$ such that $ m(a \otimes b) \coloneqq ab $; this remark is a little troubling because we do not have a clear definition of the tensor product and its relations with other algebraic structures, which will be investigated now.
	\end{Remark*}
	
	\section{Tensor Products}
	
	\begin{Definition}[Free vector space]
		Let $F(V \times W) = \mathbb K\text{-}\mathrm{span}\qty{\, (v, w) \mid v \in V,\, w \in W\, }$, called the \emph{free vector space} on $V \times W$.
	\end{Definition}
	
	\begin{Definition}[Tensor product]
		The tensor product space is the quotient:
		\begin{gather*}
		V \otimes W = F(V \times W)/I
		\end{gather*}
		where $I$ is generated by linear relations of $v$ and $w$:
		\begin{gather*}
		(v_1 + v_2, w) \sim (v_1, w) + (v_2, w) \\
		(v, w_1 + w_2) \sim (v, w_1) + (v, w_2) \\
		(cv, w) \sim (v, cw) \sim c(v, w)
		\end{gather*}
	\end{Definition}
	
	\begin{Remark*}
		The tensor $a \otimes b = \overline{(a,b)}$, an equivalence class, and $a' \otimes b'$ can be equal to $a \otimes b,\, a' \neq a, \, b' \neq b$.
	\end{Remark*}
	
	To define a linear $m \colon V \otimes W \to W$, we would have to define an $n \colon F(V \times W) \to W$ such that $n(I) = 0$, which implies that $n$ is a bilinear map. 

	\subsection{Universal Property}

	\begin{Theorem}[Universal property of tensor products]
		Let $\phi \colon V \times W \to V \otimes W$ be a bilinear map. If $f \colon V \times W \to L$ is a bilinear map, then there exists a unique linear map $\tilde f \colon V \otimes W \to L$ such that $f = \tilde f \cdot \phi $, which satisfied the commutative diagram:
		\begin{gather*}
		\xymatrix{
		V \times W \ar[r]^{\phi} \ar[rd]_{f} & V \otimes W \ar[d]^{\tilde f} \\
		& L
		}
		\end{gather*}
	\end{Theorem}

	\begin{proof}
		Let $\phi(v,w) \coloneqq {(v,w) + I} = {v \otimes w}$. The following are evident from their respective properties:
		\begin{align*}
	    	f(\lambda v, w) & = \lambda f(v,w) & (\text{bilinearity}) \\
	  		\phi(\lambda v, w) & = \phi(v,\lambda w) = \lambda(v, w) + I = \lambda(v \otimes w) & (\text{bilinearity}) \\
	    	\tilde f(\lambda (v\otimes w)) & = \lambda\tilde f(v\otimes w) \coloneqq \lambda f(v,w) & (\text{linearity})
	    \end{align*}
		Extending $\tilde f$ linearly:
		\begin{gather*}
			\tilde f\pqty{\sum_{i=1}^m \lambda_i v_i \otimes w_i } \coloneqq \sum_{i = 1}^n \lambda_i f\pqty{v_i, w_i}
		\end{gather*}
		If $\sum_{i=1}^m \lambda_i (v_i,w_i) = \sum_{j=1}^n \mu_j (x_j,y_j)$, then for the map to be well-defined, we must have:
		\begin{gather*}
			f\pqty{\sum_{i=1}^m \lambda_i (v_i,w_i)} = f\pqty{\sum_{j=1}^n \mu_j (x_j,y_j)} 
		\end{gather*}
		Because $\sum_{i=1}^m \lambda_i (v_i,w_i) - \sum_{j=1}^n \mu_j (x_j,y_j) \in I$.
	\end{proof}

	So the definitions $f$ and $\tilde f$ determine each other. We can choose bases $\qty{v_i \mid i \in I}$ and $\qty{v_j \mid j \in J}$ of $U, V$. The procedure is defining the mappings of the basis elements and extending bilinearly.  

	\subsection{Useful Examples}

	\begin{Example*}[$A$-ring]
		The problem of the tensor product on the $A$-ring can be solved now using the universal property. Since $A \times A$ filters through $A \otimes A$, the multiplication $m(a \otimes b) = ab$ directly.
	\end{Example*}

	Therefore definitions 4 and 7 are equivalent.
	
	\begin{Example*}[Isomorphisms of $\mathbb K$-algebras]
		Let $A$ be a $\mathbb K$-algebra, then $\mathbb K \otimes A \cong A$ as $\mathbb K$-algebras. From the universal property, we construct a bilinear map $f \colon \mathbb K \times A \to A$; the most natural definition for this is $f(\lambda, a) = \lambda a$. Note that this is a valid algebra homomorphism. $\Im f = \Im \tilde f$ and $\ker \tilde f$ is trivial from the bilinearity of $\phi$. This can be observed by taking a sum of tensor products:
		\begin{gather*}
			\sum_i^n \lambda_i \otimes a_i = \sum_i^n 1_{\mathbb K} \otimes \lambda_i a_i	
		\end{gather*}
		which is zero when either $\lambda_i$ or $a_i$ is zero. Another way is by constructing the inverse map $g \colon A \to \mathbb K \otimes A $, which should be $g(a) = 1_{\mathbb K} \otimes a$. This is clearly an inverse since $g(\lambda a) = 1_{\mathbb K} \otimes \lambda a = \lambda \otimes a$ from bilinearity of the tensor product.
	\end{Example*}

	\begin{Example*}[Tensor product of two $\mathbb R$-algebras]
		Let $\mathbb C$ be the complex vector space over $\mathbb R$, which forms a ring as well, and is therefore an $\mathbb R$-algebra. Then $\mathbb C \otimes \mathbb R[x] \cong \mathbb C[x]$, which is also an $\mathbb R$-algebra. Note that only reals can be transferred over the tensor product.
		Using the universal property, construct the bilinear map $f(z, p(x)) = zp(x),\, z \in \mathbb C,\, p(x) \in \mathbb R[x]$, then $\tilde f(z \otimes p(x)) = zp(x)$. This is a valid algebra homomorphism as the multiplication is preserved. To show that the kernel is trivial, take the sum of tensor products:
		\begin{gather*}
			\sum_i^n z_i \otimes p_i(x)
		\end{gather*}
		One requires bases of $\mathbb C$ and $\mathbb R[x]$ to decompose the terms into sums of their respective components, each summing to zero. Surjectivity is immediate, as every $zp(x)$ comes from $\tilde f(z \otimes p(x))$.
	\end{Example*}

	\begin{Example*}
		Does there exist a natural (linear!) map between vector spaces $V \otimes W \to V$? Try the map $f \colon V \times W \to V$, where $(v, w) \mapsto v$; however, this map is not bilinear. Try the mapping $(v,w) \mapsto [\alpha^*(w)]v$, where $\alpha^*$ is any linear functional that lives in the dual space $W^*$. The motivation for this selection is preservation of	bilinearity while deleting information of $w$. This is indeed bilinear by observing:
		\begin{gather*}
			f(v, w_1 + w_2) = \bqty{\alpha^*(w_1) + \alpha^*(w_2)}v
		\end{gather*}
		Using the universal property, take the sum of tensor products:
		\begin{gather*}
			\tilde f\pqty{\sum_{i} v_i \otimes w_i} = \sum_i \bqty{\alpha^*(w_i)}v_i
		\end{gather*}
		As an example, one can select $\alpha^*$ as projections of a basis $\qty{w_i \colon i \in I}$.
	\end{Example*}

		\begin{Lemma}\label{lem:tensProdBasis}
		If $\qty{w_j \mid j \in J}$ is a basis for $W$, and $ \sum\limits_{i=1}^n v_i \otimes w_{j_i} = 0 $	then $v_i = 0, \forall\,i \in I$.
	\end{Lemma}
	\begin{proof}
		Let $\tilde f \colon V \otimes W \to W$, using the linear map the previous example with the following linear functional:
		\begin{gather*}
			\alpha^*(w_j) \equiv 
			\begin{cases}
		        1, & j = j_k \\
		        0, & j \neq j_k 
	        \end{cases}
		\end{gather*}
		for any $k = 1, \ldots, n$. Therefore:
		\begin{gather*}
			\tilde f \pqty{\sum_{i=1}^n v_i \otimes w_{j_i}} = 0\\
			\sum_{i=1}^n \tilde f\pqty{v_i \otimes w_{j_i}} = 0 \\
			\sum_{i=1}^n \alpha^*\pqty{w_{j_i}} v_i = v_k = 0
		\end{gather*}
	\end{proof}

	Some instructive exercises are:
	\begin{gather*}
		V \otimes W \cong V \otimes W \\
		\pqty{U \otimes V} \otimes W \cong U \otimes \pqty{V \otimes W} \\
		\pqty{U \oplus V} \otimes W \cong \pqty{U \otimes W} + \pqty{V \otimes W} 
	\end{gather*}

	If $A$ is a $\mathbb K$-algebra and $\mathbb K \subset \mathbb L$, then $A \otimes_{\mathbb K} \mathbb L$ is an $\mathbb L$-algebra.

	\begin{Example*}
		$\mathbb R[x] \otimes_{\mathbb R} \mathbb C$ is a $\mathbb C$-algebra.
	\end{Example*}

	\begin{Exercise}
		Let $V$ and $W$ be $\mathbb{F}$-vector spaces. If $\qty{v_i \mid i \in I}$ is a basis for $V$ and $\qty{w_j \mid j \
		\in J}$ is a basis for $W$, prove that $\qty{v_i \otimes w_j \mid i \in I, j \in J}$ is a basis for $V \otimes W$. Conclude that, if $\dim V$ and $\dim W$ are finite, then $\dim V \otimes W = \dim V \dim W$.
	\end{Exercise}
	\begin{Solution*}
		Suppose that
		\begin{gather*}
			\sum_{i,j} \lambda_{ij} v_i \otimes w_j = 0.
		\end{gather*}
		Rewriting this,
		\begin{gather*}
			\sum_j v'_j \otimes w_j = 0,
		\end{gather*}
		where $v'_j = \sum_i \lambda_{ij} v_i$. Then, since the $w_j$ form a basis of $W$, each $v'_j = 0$ by Lemma~\ref{lem:tensProdBasis}. That is, $\sum\limits_i \lambda_{ij} v_i = 0$ for each $j$. Since the $v_i$ form a basis of $V$, this implies that each $\lambda_{ij} = 0$. Therefore $\qty{v_i \otimes w_j \mid i \in I, j \in J}$ is linearly independent.
		
		To see that the set is spanning, every element of $V \otimes W$ can be written as:
		\begin{align*}
			\sum_{k} v'_k \otimes w'_k & = \sum_k \pqty{\sum_i \alpha_{ki} v_i} \otimes \pqty{\sum_j \beta_{kj} w_j} \\
				& = \sum_{i,j} \lambda_{ij} \pqty{v_i \otimes w_j}, \quad \lambda_{ij} = \sum_k \alpha_{ki} \beta_{kj}
		\end{align*}
		The dimension of $V \otimes W$ is $\abs{\qty{\, v_i \otimes w_j \mid i \in I, j \in J \,}} = \abs{\qty{\, v_i \mid i \in I \,} } \cdot \abs{\qty{\, w_j \mid j \in J \,}} = \dim V \dim W$.
	\end{Solution*}

	\begin{Exercise}
		\begin{subquests}
			\item Prove that $\mathbb{F}[x] \otimes \mathbb{F}[x] \cong \mathbb{F}[x,y]$ as $\mathbb{F}$-algebras.
			\item  If $A$ is an $\mathbb{F}$-algebra, let $M_{n \times n}(A)$ be the $\mathbb{F}$-algebra of $n \times n$ matrices with entries in $A$. Explain briefly why $M_{n\times n}(A)$ is an $\mathbb{F}$-algebra. Prove that $M_{n \times n}(A) \cong M_{n \times n}(\mathbb F) \otimes A$ as $\mathbb{F}$-algebras.
			\item  Prove that $M_{m\times m}(\mathbb F) \otimes M_{n\times n}(\mathbb F) \cong M_{mn \times mn}(\mathbb F)$ as $\mathbb F$-algebras.
		\end{subquests}
	\end{Exercise}
	\begin{Solution*}
		\begin{subquests}
			\item Since $\mathbb F[x] \otimes \mathbb F[x]$ has a basis $\qty{\, x^i \otimes x^j \mid i, j \in \mathbb N_0 \,}$, and $\mathbb F[x, y]$ has a basis $\qty{\, x^i y^j \mid i, j \in \mathbb N_0 \,}$, the mapping $x^i \otimes x^j \mapsto x^i y^j$ defines a linear transformation (by linear extension). This transformation is an algebra homomorphism, for
			\begin{gather*}
			(x^i \otimes x^j) (x^k \otimes x^l) = x^{i + k} \otimes x^{j + l} \mapsto x^{i + k} y^{j + l} = (x^i y^j) (x^k y^l).
			\end{gather*}
			The map $x^i y^j \mapsto x^i \otimes x^j$ (linearly extended) is clearly the inverse of the above homomorphism, which shows that $\mathbb F[x] \otimes \mathbb F[x] \cong \mathbb F[x, y]$.
			\item Matrices form a vector space, the multiplication is given by matrix multiplication, and the identity matrix is the $1$ of the ring, so the copy of the field is the set of scalar multiples of the identity matrix.
			
			Define a map $M_{n \times n} (\mathbb F) \otimes A \to M_{n \times n}(A)$, $\sum\limits_k \Lambda_k \otimes a_k \mapsto \sum\limits_k \Lambda_k a_k$, where $\Lambda_k = \bqty{\lambda^{(k)}_{ij}}$ is a matrix in $M_{n \times n}(\mathbb F)$ and $a_k \in A$ for each $k$. This map is obviously a linear transformation, and since $\pqty{\sum\limits_k \Lambda_k \otimes a_k}\pqty{\sum\limits_l \Gamma_l \otimes b_l} = \sum\limits_{k, l} \Lambda_k \Gamma_l \otimes a_k b_l \mapsto \sum\limits_{k, l} \Lambda_k \Gamma_l a_k b_l$, it is an algebra homomorphism as well. If the kernel is trivial, then this is an isomorphism. Therefore, consider $\sum\limits_k \Lambda_k \otimes a_k \mapsto \sum\limits_k \Lambda_k a_k = 0$. Then, for each $i$, $j$, we have $\sum\limits_k \lambda^{(k)}_{ij} a_k = 0$. Let $E_{ij}$ be the $n \times n$ $\mathbb F$-matrix with $(i,j)$-entry $1$ and all other entries $0$. Then,
			\begin{align*}
				\sum_k \Lambda_k \otimes a_k & = \sum_k \pqty{\sum_{i,j} \lambda^{(k)}_{ij} E_{ij}} \otimes a_k\\
					& = \sum_{i,j} E_{ij} \otimes \pqty{\sum_k \lambda^{(k)}_{ij} a_k}\\
					& = \sum_{i, j} E_{ij} \otimes 0\\
					& = 0.
			\end{align*}
			Thus, the kernel is trivial and the mapping is an isomorphism of algebras.
			\item Since each one forms an $\mathbb F$-algebra, the previous definition can be used.
		\end{subquests}
	\end{Solution*}

	\subsection{Graded Algebras}

	\begin{Definition}[Graded algebras]
		An algebra $A$ is \emph{graded} if there exists a decomposition
		\begin{gather*}
			A = A_0 \oplus A_1 \oplus A_2 \oplus \cdots
		\end{gather*}
		such that $A_i A_j \subseteq A_{i+j}, \forall i,j$, where $A_i$ stands for homogenous elements of degree $i$.
	\end{Definition}

	\begin{Example*}[Polynomial ring]
		The polynomial ring has a decomposition:
		\begin{gather*}
			\mathbb K[x] = \bigoplus_{i=0}^{\infty} \mathbb K x^i
		\end{gather*}
	\end{Example*}

	\begin{Example*}[Multivariate polynomial ring]
		The multivariate polynomial ring has the following decomposition:
		\begin{gather*}
			\mathbb K[x_1,\ldots,x_n] = \bigoplus_{d=0}^{\infty} A_d
		\end{gather*}
		where $A_d = \mathbb K\qty{x_1^{a_1},\ldots, x_n^{a_n}\mid a_1 + \ldots + a_n = d, a_i \geq 0}$. The dimension $d$ is found by solving the problem of partitioning $d$ into $n$ multisets ignoring the relative positioning, which is $\binom{n+d-1}{d}$. This combinatorial problem's answer is explained later in the exercise of the \emph{symmetric algebra}.
	\end{Example*}

	\begin{Example*}[Permutation algebra]
		The permutation algebra, denoted earlier as $\mathbb KP$, has the following decomposition:
		\begin{gather*}
			\mathbb KP = \bigoplus_{n=0}^{\infty} \mathbb KP_n
		\end{gather*}
		where $P_n$ is from the same investigation of the permutation algebra.
	\end{Example*}

	\begin{Note*}
		An ideal $I$ is called \emph{homogeneous} if it is generated by homogeneous elements. If $A$ is a graded algebra, then $A/I$ is also a graded algebra if $I$ is homogeneous.
	\end{Note*}

	\begin{Definition}[Hilbert series]
		The \emph{Hilbert series} of a graded algebra $A$ is a generating function:
		\begin{gather*}
			\Hilb(A; q) = \sum_{d=0}^{\infty} \dim\pqty{A_d} q^d
		\end{gather*}
		which generates the $d$\th dimension of the decomposition of a graded algebra as the $d$\th coefficient of a power series.
	\end{Definition}

	\begin{Example*}
		The multivariate polynomial ring has the Hilbert series:
		\begin{gather*}
			\Hilb\pqty{\mathbb K[x_1,\ldots, x_n]; q} = \sum_{n=0}^{\infty} \binom{n + d - 1}{n} q^n
		\end{gather*}
	\end{Example*}

	\begin{Exercise}
		Let $V$ be a given $d$-dimensional $\mathbb F$-vector space for some $d \in \mathbb N$ and let $V^{\otimes k} = V \otimes \dots \otimes V$ (where there are $k$ copies of $V$) be the \emph{$k$\th tensor power of $V$}.
		\begin{subquests}
			\item Find the Hilbert series of the \emph{tensor algebra}, defined as:
			\begin{gather*}
				T(V) = \bigoplus_{k=0}^{\infty} V^{\otimes k} = F \oplus V \oplus V^{\otimes 2} \oplus V^{\otimes 3} \oplus \cdots
			\end{gather*}			

			\item Find the Hilbert series of the \emph{symmetric algebra} of $V$, defined as:
			\begin{gather*}
			 	S(V) = T(V)/\langle u \otimes v - v \otimes u \mid u,v \in V \rangle
			 \end{gather*} 

			\item Find the Hilbert series of the \emph{exterior algebra} of $V$, defined as:
			\begin{gather*}
				\bigwedge(V) = T(V)/\langle v \otimes v \mid u,v \in V \rangle
			\end{gather*}
		\end{subquests}
	\end{Exercise}
	\begin{Solution*}
		\begin{subquests}
			\item The dimension of $V^{\otimes k}$ is $d^k$, so the Hilbert series is:
			\begin{gather*}
				\Hilb(T(V);q) = \sum_{k=0}^{\infty}d^k q^k = \frac{1}{1-dq}
			\end{gather*}
			
			\item The quotient introduces commutativity of the tensor product as another condition into the free vector space. Extending this using the associativity of the tensor product, the cross terms are reduced by their symmetries in the $k$\th dimension. This analysis is done most easily by borrowing index notation of tensors, which is extensively used in general relativity.

			Let a tensor $T$ of $k$\th dimension be denoted by using $k$ indices: $T_{\alpha\beta\gamma\dots}$, where $\alpha,\beta,\gamma \dots$ each range from $1$ to $d$, so the dimension of the tensor is $d^k$ when there are no symmetries. Symmetry between indices is denoted as equality upon interchange of the relative index placements. For example, $T_{\alpha\beta\gamma\mu} = T_{\alpha\mu\gamma\beta}$ denotes symmetry of the tensor in $\beta$ and $\mu$. Take a tensor with $k$ indices that is symmetric in all of them. The symmetric part is completely specified by the multisets of length $k$ with the entries ranging from $1$ to $d$. So the problem reduces to partitioning $k$ objects into $d$ sets ignoring the relative positioning. Since there are $d-1$ spaces and $k$ dividers, the number of ways of choosing $k$ places for the objects is $\binom{k+d-1}{k}$. These are the number of independent components of the symmetric tensor $T \in V^{\otimes k}$, and hence its dimension. Therefore, the Hilbert series is:
			\begin{gather*}
				\Hilb(S(V);q) = \sum_{k=0}^{\infty} \binom{k+d-1}{k} q^k = \dfrac 1 {(1 - q)^d}
			\end{gather*}

			\item In the quotient algebra, $v \otimes v = 0$. This also implies that $u \otimes v = - v \otimes u$, which is easily seen by using bilinearity to expand $(u + v) \otimes (u + v) = 0$ and rearranging the non-zero terms. Therefore, in the quotient of the $k$\th tensor power $V^{\otimes k}$, any product $v_1 \otimes v_2 \otimes \cdots \otimes v_k$ is zero if any two of its terms are equal ($v_i = v_j$, $i \ne j$). Two products $u_1 \otimes \cdots \otimes u_k$ and $v_1 \otimes \cdots \otimes v_k$ are equal up to a difference in sign if one is obtained from the other by any permutation of terms. Thus, if $\qty{v_1, v_2, \cdots, v_d}$ is a basis of $V$, then a basis for $V^{\otimes k}$ consists of elements of the form $v'_1 \otimes v'_2 \otimes \cdots \otimes v'_k$, where each $v'_i$ is some basis vector $v_j$, and all the $v'_i$ are distinct, with no two elements being equivalent under rearrangement of terms. In other words, every basis element of $V^{\otimes k}$ corresponds to a selection of $d$ distinct basis vectors from the $k$ basis vectors of $V$. Thus, the dimension is $\binom d k$. Therefore, the Hilbert series is:
			\begin{gather*}
				\Hilb\pqty{\bigwedge(V);q} = \sum_{k=0}^{\infty} \binom d k q^k = (1 + q)^d
			\end{gather*}
 		\end{subquests}
	\end{Solution*}


	\section{Coalgebras}

	\begin{Definition}[Coalgebra]
		A \emph{coalgebra} is a $\mathbb K$-vector space $C$ with linear maps
		\begin{center}
			\begin{tabular}{rl}
		 		Comultiplication: & $\Delta \colon C \rightarrow C \otimes C$ \\
		 		Counit: & $ \epsilon \colon \mathbb K \rightarrow C$ 
		\end{tabular}
		\end{center}
		such that the following diagrams commute:
		\begin{align*}
		\xymatrix{
			C \otimes C \otimes C & C \otimes C \ar[l]_-{\id \otimes \Delta} \\
			C \otimes C \ar[u]^-{\Delta \otimes \id} & C \ar[l]^-{\Delta} \ar[u]_-{\Delta}
		} & &
		\xymatrix{
			\mathbb K \otimes C  & C \otimes C \ar[l]_-{\epsilon \otimes \id} \ar[r]^-{\id \otimes \epsilon} & C \otimes \mathbb K  \\
			& C \ar[u]^-{\Delta} \ar[lu]^-{\pqty{1 \otimes -}} \ar[ru]_-{\pqty{- \otimes 1}} &	
		}
		\end{align*}
	\end{Definition}
	\begin{Remark*}
		These diagrams encode properties called \emph{coassociativity} and \emph{counitarity}.
	\end{Remark*}
	\begin{Example}[Set coalgebra]
		Let $\mathbb K S$ be a vector space generated by the set $S$. Define the following maps:
		\begin{gather*}
			\Delta(s) = s\otimes s \\
			\epsilon(s) = 1 
		\end{gather*}
		Checking coassociativity:
		\begin{gather*}
			\pqty{\Delta \otimes \id} \pqty{s \otimes s} = s \otimes s \otimes s \\
			\pqty{\id \otimes \Delta} \pqty{s \otimes s} = s \otimes s \otimes s 
		\end{gather*}
		Checking counitarity:
		\begin{gather*}
			\pqty{\epsilon \otimes \id} \pqty{s \otimes s} = 1 \otimes s \equiv s \\
			\pqty{\id \otimes \epsilon} \pqty{s \otimes s} = s \otimes 1 \equiv s
		\end{gather*}
	\end{Example}

	\begin{Example}[Incidence coalgebra]
		Let $P$ be a poset. For $x \leq y$, the \emph{interval} is defined as $\bqty{x,y} = \qty{\, x \leq z \leq y \mid \, z \in P \,}$. Denote the set of all intervals in $P$ as $\mathrm{Int}(P) \coloneqq \qty{\, \bqty{x,y} \mid x \leq y \in P \,}$. The \emph{incidence coalgebra} is defined as $C \coloneqq \mathbb K \mathrm{Int}(P)$. Define the following:
		\begin{gather*}
			\Delta\bqty{x,y} = \sum_{z \in [x, y]} \bqty{x,z} \otimes \bqty{z,y} \\
			\epsilon{\bqty{x,y}} =
			\begin{cases}
				1, & x = y \\
				0, & x < y
			\end{cases}
		\end{gather*}
		Checking coassociativity:
		\begin{gather*}
			\pqty{\Delta \otimes \id}\pqty{\sum_{z \in [x, y]} \bqty{x,z} \otimes \bqty{z,y}} = \sum_{z \in [x, y]}\pqty{\sum_{z' \in [x, z]} \bqty{x,z'} \otimes \bqty{z',z}} \otimes \bqty{z,y} \\
			\pqty{\id \otimes \Delta}\pqty{\sum_{z \in [x, y]} \bqty{x,z} \otimes \bqty{z,y}} = \sum_{z \in [x, y]} \bqty{x,z} \otimes \pqty{\sum_{z' \in [z, y]} \bqty{z,z'} \otimes \bqty{z',y}}
		\end{gather*}
		Checking counitarity:
		\begin{gather*}
		\pqty{\epsilon \otimes \id} \pqty{\sum_{z \in [x, y]} [x, z] \otimes [z, y]} = \sum_{z \in [x, y]} \epsilon [x, z] \otimes [z, y] = 1 \otimes [x, y]\\
		\pqty{\id \otimes \epsilon} \pqty{\sum_{z \in [x, y]} [x, z] \otimes [z, y]} = \sum_{z \in [x, y]} [x, z] \otimes \epsilon [z, y] = [x, y] \otimes 1
		\end{gather*}
	\end{Example}

	\begin{Exercise}
		In a coalgebra, we say the element $x$ is grouplike if $\Delta(x) = x \otimes x$. Prove that in the group ring $\mathbb F[G]$, $x$ is grouplike if and only if $x \in G$.
	\end{Exercise}
	\begin{Solution*}
		Let $x = \sum\limits_{i = 1}^n \lambda_i g_i \in \mathbb F[G]$ be grouplike. Then:
		\begin{align*}
		\Delta(x) & = x \otimes x \\
		\Delta\pqty{\sum_{i=1}^n \lambda_i g_i} & = \pqty{\sum_{i=1}^n \lambda_i g_i} \otimes \pqty{\sum_{i=1}^n \lambda_i g_i}
		\end{align*}
		Using linearity of the coproduct and bilinearity of the tensor product:
		\begin{align*}
		\sum_{i=1}^n \lambda_i \pqty{g_i \otimes g_i} & = \pqty{\sum_{i=1}^n \lambda_i g_i} \otimes \pqty{\sum_{j=1}^n \lambda_j g_j}\\
		\sum_{i=1}^n \pqty{g_i \otimes \lambda_i g_i} & = \sum_{i=1}^n \pqty{g_i \otimes \lambda_i \sum_{j=1}^n \lambda_j g_j}
		\end{align*}
		\begin{align*}
		& \sum_{i=1}^n  \pqty{ g_i \otimes \lambda_i g_i} - \sum_{i=1}^n  \pqty{ g_i \otimes \lambda_i \sum_{j=1}^n \lambda_j g_j} = 0 \\
		& \sum_{i=1}^n  \bqty{g_i \otimes \lambda_i\pqty{g_i - \sum_{j=1}^n \lambda_j g_j}} = 0
		\end{align*}
		Since $g_i$ form the basis of the group ring, Lemma~\ref{lem:tensProdBasis} implies that for each $i$, the second argument of the tensor product is zero. Thus, for each $i = 1, \ldots, n$:
		\begin{gather*}
		\lambda_i = 0 \quad \text{or} \quad \sum_{j=1}^n \lambda_j g_j = g_i
		\end{gather*}
		This implies that if $\lambda_i \ne 0$ for some $i$, then, since $g_i$ are basis elements, $\lambda_j = 0$ for all $j \ne i$ and $\lambda_i = 1$. That is, $\lambda_i$ is non-zero for at most one $i$, in which case $\lambda_i = 1$. Thus, $x = \sum\limits_{i = 1}^n \lambda_i g_i = g_i$ or $x = 0$.
	\end{Solution*}
	
	\begin{Exercise}
		Consider the $\mathbb F$-algebra $H_4$ generated by indeterminates $g$ and $x$ subject to the relations $g^2 = 1, x^2 = 0$ and $xg = -gx$.
		\begin{subquests}
			\item Show that $1, g, x$ and $gx$ form a basis for $H_4$.
			\item Express the product $(a_1 + b_1 g + c_1 x + d_1 gx)(a_2 + b_2 g + c_2 x + d_2 gx)$ in terms of this basis, where $a_i, b_i, c_i, d_i \in \mathbb F, i = 1, 2$.
			\item Show that the coproduct $\Delta g = g \otimes g$ and $\Delta x = x \otimes 1 + g \otimes x$ and the counit given by $\epsilon(g) = 1$ and $\epsilon(x) = 0$ turn $H_4$ into a bialgebra.
			\item Express the coproduct $\Delta(a + bg + cx + dgx)$ in terms of this basis.
		\end{subquests}
	\end{Exercise}
	\begin{Solution*}
		\begin{subquests}
			\item Any expression $g^m$ reduces to either $g$ or $1$ depending on $m$ is odd or even. Any expression $x^m$ reduces to zero for $m > 1$. Therefore, any expression containing more than one $x$ will reduce to zero using the anticommutation relation between $g$ and $x$. Thus, any non-zero expression is of the form $g^m x g^n$, which reduces to an expression of the form $\pm gx$ or $\pm x$. Therefore, these four elements form a basis for the algebra.
			
			\item The product is $\pqty{a_1 a_2 + b_1 b_2} + \pqty{a_1 b_2 + a_2 b_1 + b_1 d_2 + b_2 d_1}g + \pqty{a_1 c_2 + a_2 c_1}x + \pqty{a_1 d_2 + a_2 d_1 + b_1 c_2 + b_2 c_1}gx $.
			
			\item Since $\Delta$ and $\epsilon$ are algebra homomorphisms:
			\begin{align*}
			\Delta(gx) & = \Delta g \Delta x = \pqty{g \otimes g}\pqty{x \otimes 1 + g \otimes x} = gx \otimes g + 1 \otimes gx \\
			\epsilon(gx) & = \epsilon(g) \epsilon(x) = 0\\
			\Delta(1) & = 1 \otimes 1, \quad \epsilon(1) = 1
			\end{align*}
			Coassociativity holds:
			\begin{align*}
			(\id \otimes \Delta) \Delta g & = g \otimes g \otimes g = (\Delta \otimes \id) \Delta g \\
			(\id \otimes \Delta) \Delta x & = (\id \otimes \Delta) \bqty{x \otimes 1 + g \otimes x} \\
			& = x \otimes 1 \otimes 1 + \pqty{g \otimes x \otimes 1 + g \otimes g \otimes x} \\
			(\Delta \otimes \id) \Delta x & = (\Delta \otimes \id)\bqty{x \otimes 1 + g \otimes x} \\
			& =  \pqty{x \otimes 1 \otimes 1 + g \otimes x \otimes 1} + g \otimes g \otimes x \\
			(\id \otimes \Delta)\Delta (gx) & = (\id \otimes \Delta)\pqty{gx \otimes g + 1 \otimes gx} \\
			& = gx \otimes g \otimes g + \pqty{1 \otimes gx \otimes g + 1 \otimes 1 \otimes gx} \\
			(\Delta \otimes \id)\Delta (gx) & = (\Delta \otimes \id)\pqty{gx \otimes g + 1 \otimes gx} \\
			& = \pqty{gx \otimes g \otimes g + 1 \otimes gx \otimes g} + 1 \otimes 1 \otimes gx
			\end{align*}
			Similarly, counitarity holds:
			\begin{align*}
			(\epsilon \otimes \id) \Delta g & = \epsilon (g) \otimes g = 1 \otimes g\\
			(\id \otimes \epsilon) \Delta g & = g \otimes \epsilon(g) = g \otimes 1\\
			(\epsilon \otimes \id) \Delta x & = \epsilon(x) \otimes 1 + \epsilon(g) \otimes x = 1 \otimes x\\
			(\id \otimes \epsilon) \Delta x & = x \otimes \epsilon(1) + g \otimes \epsilon(x) = x \otimes 1\\
			(\epsilon \otimes \id) \Delta(gx) & = \epsilon(gx) \otimes g + \epsilon(1) \otimes gx = 1 \otimes gx\\
			(\id \otimes \epsilon) \Delta(gx) & = gx \otimes \epsilon(g) _ 1 \otimes \epsilon(gx) = gx \otimes 1
			\end{align*}
			These form a bialgebra by definition of $\Delta$ and $\epsilon$ as algebra homomorphisms.
			
			\item $\Delta(a + bg + cx + dgx) = a \otimes 1 + b(g \otimes g) + c(x \otimes 1 + g \otimes x) + d(gx \otimes g + 1 \otimes gx)$ 
		\end{subquests}
	\end{Solution*}

	\subsection{Duality}

	\begin{Definition}[Duality of vector spaces]
		If $V$ is a $\mathbb K$-vector space, then the dual vector space is $V^* \coloneqq \Hom_{\mathbb K}(V, \mathbb K)$.
	\end{Definition}

	\begin{Remark*}
		A \emph{finite-dimensional} vector space $V$ is isomorphic to its dual space $V^*$, and \emph{naturally isomorphic} to its double dual $V^{**} \coloneqq (V^*)^*$. These definitions are extended to algebras and coalgebras:
		
		If $C$ is a coalgebra, then $C^*$ is naturally an algebra. If $A$ is a \emph{finite-dimensional} algebra, then $A^*$ is a coalgebra.
	\end{Remark*}

	Dirac's bra-ket notation, which is used in quantum physics, will be used to denote elements of linear algebra. In this notation, vectors are denoted by `\emph{kets}' $\ket{v} \in V$, dual vectors are denoted by `\emph{bras}' $\bra{v} \in V^* $. The notation for tensors is denoted as follows: $\ket{v} \otimes \ket{w} \equiv \ket{v \otimes w} \in V \otimes W$.

	The inner product of two vectors is defined as the bilinear map $\braket{-}{-} \colon V \times V \to \mathbb K$, such that $\braket{v_1}{v_2} \coloneqq v_1^*(v_2), \bra{v_1} \in V^*, \ket{v_2} \in V$. This is generalised to the tensor product of vector spaces in the following manner:

	\begin{Definition}[Inner product of tensors]
		The \emph{inner product of tensors} is defined as the map $\braket{- \otimes -}{- \otimes -} \colon \pqty{V \otimes W} \times \pqty{V \otimes W} \to \mathbb K$, such that $ \braket{v_1 \otimes w_1}{v_2 \otimes w_2} \coloneqq \braket{v_1}{v_2}\braket{w_1}{w_2}$.
	\end{Definition} 

	\begin{Remark*}
		The definition of this map requires the construction of the following map $\rho \colon {V^* \otimes W^*} \to \pqty{V \otimes W}^*$, such that $\bra{v} \otimes \bra{w} \mapsto \bra{v \otimes w}$. This is an injective map, as the following argument shows. Suppose that $\bra{v \otimes w} = \bra 0$ for some $v$ and $w$. Then in particular, $\braket{v \otimes w} = \braket v \braket w = 0$, which means that either $\bra v = 0$ or $\bra w = 0$, and therefore, $\bra v \otimes \bra w = 0$. Thus, $\ker \rho$ is trivial, and $\rho$ is injective. When $V$ and $W$ are finite-dimensional, $\rho$ is bijective.
 	\end{Remark*}

 	\begin{Remark*}[\emph{Important}]
 		For any linear map $f \colon V \to W$, there exists a dual map $f^* \colon W^* \to V^*$, such that $\braket{f^*(w)}{v} = \braket{w}{f(v)}$.
 	\end{Remark*}

 	To extend this concept to algebras and coalgebras, we introduce duals of algebras. But first, we discuss important tools that will be handy in the future.

 	\begin{Theorem}[Categorical imperative]
 		Every proposition can be proved using commutative diagrams.	
 	\end{Theorem}

 	\begin{proof}
 		Ask Kant.
 	\end{proof}
 
 	\begin{Definition}[Dual of a coalgebra]
 		Let $C$ be a coalgebra with the comultiplication $\Delta \colon C \to C \otimes C$ and counit $\epsilon \colon C \to \mathbb K$. Let $C^*$ be the dual of $C$ with multiplication and unit defined by the following diagrams:
 		\begin{align*}
			\xymatrix{
				C^* \otimes C^* \ar[rr]^-{m} \ar[rd]_-{\rho} & & C^* \\
				& \pqty{C \otimes C}^* \ar[ru]_-{\Delta^*}
			} & &
			\xymatrix{
				\mathbb K \ar[rr]^-{u} \ar[rd]_-{\cong_{\mathbb K}} & & C^* \\
				& \mathbb K^* \ar[ru]_-{\epsilon^*}
			}
		\end{align*}
 	\end{Definition}
 	Similarly, the dual of a \emph{finite-dimensional} algebra $\pqty{A, m, u}$, denoted as $A^*$ forms a coalgebra with the comultiplication $\Delta \colon A^* \to A^* \otimes A^*$ and counit $\epsilon \colon A^* \to \mathbb K$.
 	
 	Compositions are ``reversed" by duals. For linear maps $\xymatrix{V \ar[r]^f & W \ar[r]^g & X}$, we have $\braket{x}{g(f(v))} = \braket{g^*(x)}{f(v)} = \braket{f^*(g^*(x))}{v}$, which shows that $(g \circ f)^* = f^* \circ g^*$. The following lemma is immediate from this observation.
 	
 	\begin{Lemma}
 		The dual of a commutative diagram is also commutative.
 	\end{Lemma}
 	
 	\begin{Remark*}
 		The \emph{dual} of a diagram is the one obtained by replacing every vector space by its dual space and every linear map by its dual map, which naturally involves reversing all arrows.
 	\end{Remark*}

 	\begin{Example*}[Incidence algebra]
 		The \emph{incidence algebra} $C^*(P)$ is defined as the dual of the incidence coalgebra $C(P)$. The elements of this algebra are linear functionals $c^* \colon C(P) \to \mathbb K$ as functions of the form $c^* \colon \mathrm{Int}(P) \to \mathbb K$. The multiplication $m \colon C^* \otimes C^* \to C^* \equiv \Delta^* \rho$ (from the commutative diagram) is defined as $c^* \otimes d^* \mapsto c^* d^*$ such that:
 		\begin{gather*}
 			\braket{\Delta^*\pqty{c \otimes d}}{[x,y]} = \braket{c \otimes d}{\Delta[x,y]} \coloneqq \sum_{z \in [x,y]} c^*\pqty{[x,z]}d^*\pqty{[z,y]}
 		\end{gather*}
 		The unit $u \colon K \to \mathbb C^* \equiv \bqty{\epsilon^* \cdot \cong_{\mathbb K}}$ is defined accordingly:
 		\begin{gather*}
 			\braket{u(1)}{[x,y]} = \braket{\epsilon^*(1)}{[x,y]} = \braket{1}{\epsilon[x,y]} =
 			\begin{cases}
 				1, & x = y \\
 				0, & x < y
 			\end{cases}
 		\end{gather*}
 	\end{Example*}
 	
 	\begin{Exercise}
 		Prove that $\pqty{C^*, m, u}$ forms an algebra.
 	\end{Exercise}
 	\begin{Solution*}
 		The duals of the comultiplication and counit commutative diagrams are:
 		\begin{align*}
		\xymatrix{
			\pqty{C \otimes C \otimes C}^* \ar[r]^-{\pqty{\id \otimes \Delta}^*} \ar[d]_{\pqty{\Delta \otimes \id}^*} & \pqty{C \otimes C}^*   \ar[d]^-{\Delta^*} \\
			\pqty{C \otimes C}^* \ar[r]_-{\Delta^*} & C^*
		} & &
		\xymatrix{
			\pqty{\mathbb K \otimes C}^* \ar[r]^-{\pqty{\epsilon \otimes \id}^*} \ar[rd]_{\pqty{1 \otimes -}^*} & \pqty{C \otimes C}^* \ar[d]^{\Delta^*} & \pqty{C \otimes \mathbb K}^* \ar[l]_-{\pqty{\id \otimes \epsilon}^*} \ar[ld]^{\pqty{-\otimes 1}^*} \\
			& C^* &	
		}
		\end{align*}
		Using the multiplication commutative diagram for $C^*$ in the first diagram:
		\begin{align*}
		\xymatrix{
			& & C^* \otimes C^* \ar[rd]^-{\rho} & &  \\
			& \pqty{C \otimes C}^* \otimes C^* \ar[rd]^-{\rho_{(1)2}} \ar[ru]^-{\Delta^* \otimes \id} & & \pqty{C \otimes C}^* \ar[rd]^-{\Delta^*} & \\
			{C^* \otimes C^* \otimes C^*} \ar[ru]^-{\rho \otimes \id} \ar[rd]_-{\id \otimes \rho} & & \pqty{C \otimes C \otimes C}^* \ar[ru]^-{\pqty{\Delta \otimes \id}^*} \ar[rd]_-{\pqty{\id \otimes \Delta}^*} & & C^*\\
			& C^* \otimes \pqty{C \otimes C}^* \ar[ru]_-{\rho_{1(2)}} \ar[rd]_-{\id \otimes \Delta^*} & & \pqty{C \otimes C}^* \ar[ru]_-{\Delta^*} & \\  
			& & C^* \otimes C^* \ar[ru]_-{\rho} & & 
			}
		\end{align*}
 	\end{Solution*}
	
	\subsection{Sweedler Notation}

	In a coalgebra, the map $\Delta \colon C \to C \otimes C$ is defined in general as:
	\begin{gather*}
		\Delta(c) = \sum_i c_{1_i} \otimes c_{2_i}	
	\end{gather*}
	To avoid the double subscripts, the following notation for the coproduct introduced by Sweedler is useful:
	\begin{gather*}
		\Delta(c) = \sum_{(c)} c_{(1)} \otimes c_{(2)}, \;\;\; c_{(1)}, c_{(2)} \in C
	\end{gather*}
	The index $(c)$ helps keep track of which `$c$' the coproduct will be taken of in further coproduct operations. This will be elucidated in the coassociativity property by comparison with the previous notation. Using the comultiplication commutative diagram:
	\begin{gather*}
		\pqty{\Delta \otimes \id}\Delta(c) = \pqty{\Delta \otimes \id}\pqty{\sum_{(c)} c_{(1)} \otimes c_{(2)}} = \sum_{(c)} \Delta c_{(1)} \otimes c_{(2)} = \sum_{(c)} c_{(1)} \otimes c_{(2)} \otimes c_{(3)} \\
		\pqty{\id \otimes \Delta}\Delta(c) = \pqty{\id \otimes \Delta}\pqty{\sum_{(c)} c_{(1)} \otimes c_{(2)}} = \sum_{(c)} c_{(1)} \otimes \Delta c_{(2)} = \sum_{(c)} c_{(1)} \otimes c_{(2)} \otimes c_{(3)}
	\end{gather*}
	It is important to note that the double summation induced by the second coproduct is reduced to a single summation by relabeling the indices, since all the elements belong to $C$. Since $\Delta$ is coassociative, the following notation is used:
	\begin{gather*}
		\Delta_2(c) = \pqty{\Delta \otimes \id}\Delta(c) = \pqty{\id \otimes \Delta}\Delta(c) = \sum_{(c)} c_{(1)} \otimes c_{(2)} \otimes c_{(3)}
	\end{gather*}
	Using the multiple subscript notation, the following unreadable mess is obtained:
	\begin{gather*}
		\Delta_2(c) = \sum_j \sum_i c_{1_{i_j}} \otimes c_{2_{i_j}} \otimes c_{3_i}
	\end{gather*}
	The operation of multiple coproducts is easily generalised:
	\begin{gather*}
		\Delta_{n-1}(c) = \sum_{(c)} c_{(1)} \otimes c_{(2)} \otimes \dots \otimes c_{(n)} 
	\end{gather*}
	Using the universal property of the tensor product:
	\begin{gather*}
		\tilde{f} \Delta_{n-1}(c) = \sum_{(c)} f(c_1, c_2, \dots, c_n)
	\end{gather*}
	Coassociativity in Sweedler notation is written as:
	\begin{gather*}
		\sum_{(c)} \Delta c_{(1)} \otimes c_{(2)} = \sum_{(c)} c_{(1)} \otimes \Delta c_{(2)}
	\end{gather*}
	Using the counitary commutative diagram:
	\begin{gather*}
		\pqty{\epsilon \otimes \id}\Delta(c) = \pqty{\epsilon \otimes \id} \sum_{(c)} c_{(1)} \otimes c_{(2)} = \sum_{(c)} \epsilon\pqty{c_{(1)}} \otimes c_{(2)} \\
		\pqty{\id \otimes \epsilon}\Delta(c) = \pqty{\id \otimes \epsilon} \sum_{(c)} c_{(1)} \otimes c_{(2)} = \sum_{(c)} c_{(1)} \otimes \epsilon\pqty{c_{(2)}} 
	\end{gather*}

	% \begin{Exercise}[Practice with Sweedler notation]
	% 	\begin{subquests}
	% 		\item Let $T \colon C \otimes C \to C \otimes C$ be the \emph{twist} map given by $T(c \otimes d) = d \otimes c$ for $c, d \in C$. Write $T \Delta(c)$ in Sweedler notation.
	% 		\item Prove the following identities:
	% 		\begin{subquests}
	% 			\item $\Delta(c) = \epsilon\pqty{c_{(2)}} \otimes \Delta\pqty{c_{(1)}}$
	% 			\item $\Delta(c) = c_{(1)} \otimes \epsilon\pqty{c_{(3)}} \otimes c_{(2)}$
	% 			\item $c = \epsilon\pqty{c_{(1)}} \otimes \epsilon\pqty{c_{(3)}} \otimes c_{(2)}$
	% 		\end{subquests}
	% 	\end{subquests}
	% \end{Exercise}
	% \begin{Solution*}
	% 	\begin{subquests}
	% 		\item $T \Delta(c) = T \pqty{c_{(1)} \otimes c_{(2)}} = c_{(2)} \otimes c_{(1)}$.

	% 		\item \begin{subquests}
	% 			\item This is equivalent to proving that $\Delta = (\epsilon \otimes \Delta) T \Delta$.
	% 			\begin{align*}
	% 			(\epsilon \otimes \Delta) T \Delta & = (\epsilon \otimes \id \otimes \id) (\id \otimes \Delta) T \Delta \\
	% 				& = (\epsilon \otimes \id \otimes \id) T (\Delta \otimes \id) \Delta \\
	% 				& = T (\id \otimes \epsilon \otimes \id) (\id \otimes \Delta) \Delta \\
	% 				& = T (\id \otimes (1 \otimes -)) \Delta \\
	% 				& \cong (1 \otimes - \otimes -) \Delta \\
	% 				& = 1 \otimes \Delta \\
	% 				& \cong \Delta
	% 			\end{align*}
	% 			\item We need to prove that $\Delta = (\id \otimes \epsilon \otimes \id) (\id \otimes T) \Delta_2$.
	% 			\begin{align*}
	% 			(\id \otimes \epsilon \otimes \id) (\id \otimes T) \Delta_2 & = (\id \otimes T) (\id \otimes \id \otimes \epsilon) (\Delta \otimes \id) \Delta \\
	% 				& = (\id \otimes T_{\mathbb K \otimes C}) (\id \otimes (1 \otimes -)) \Delta \\
	% 				& = (\id \otimes (- \otimes 1)) \Delta \\
	% 				& \cong \Delta
	% 			\end{align*}
	% 			\item The right hand side is the result of application of:
	% 			\begin{align*}
	% 			(\epsilon \otimes \epsilon \otimes \id) (\id \otimes T) \Delta_2 & = (\id \otimes T) (\epsilon \otimes \id \otimes \epsilon) (\id \otimes \Delta) \Delta \\
	% 			& = (\id \otimes T) (\epsilon \otimes (- \otimes 1)) \Delta \\
	% 			& = (\epsilon \otimes (1 \otimes -)) \Delta \\
	% 			& \cong (\epsilon \otimes \id) \Delta \\
	% 			& = 1 \otimes - \\
	% 			& \cong \id
	% 			\end{align*}
	% 		\end{subquests}
	% 	\end{subquests}	
	% \end{Solution*}

	\subsection{Homomorphisms}
	Like the reworking of Definition \ref{def:k-Alg-1} into commutative diagrams, we will rework Definition \ref{def:alghom}, the algebra homomorphism, into a commutative diagram as well.

	\begin{Definition}
		The linear map $f\colon A \to B$, where $A$ and $B$ are algebras, is a $\mathbb K$-\emph{algebra homomorphism} if and only if the following diagrams commute:
		\begin{align*}
			\xymatrix{
				A \otimes A \ar[r]^-{f \otimes f} \ar[d]_-{m_A} & B \otimes B \ar[d]^-{m_B}  \\
				A  \ar[r]_-{f} & B
			} & & 
			\xymatrix{
				A \ar[rr]^-{f} & & B \\
				& \mathbb K \ar[lu]^-{u_{A}} \ar[ru]_-{u_B} & 
			}
		\end{align*}
		$f$ is a vector space homomorphism by definition; the diagrams encode the properties of a ring. The first diagram encodes the property $f(a_1 a_2) = f(a_1)f(a_2)$. This is easily shown:
		\begin{align*}
			 \bqty{f\cdot m_A}\pqty{a_1 \otimes a_2} & = \bqty{m_b\cdot(f \otimes f)}\pqty{a_1 \otimes a_2} \\
			 f\pqty{a_1 a_2} & = m_b\pqty{f(a_1) \otimes f(a_2)} \\
			 f\pqty{a_1 a_2} & = f(a_1)f(a_2) 
		\end{align*}
		The second diagram encodes unitarity $\bqty{f\cdot u_A} \equiv u_B$.
	\end{Definition}
	
	\begin{Definition}[Subalgebras]
		Let $B$ be a $\mathbb K$-algebra and $A \subseteq B$. Then $A$ is a \emph{subalgebra} if $m(A \otimes A) \subseteq A$ and $1_{B} \subset A$.
	\end{Definition}
	More generally, $A$ is a \emph{two-sided ideal} if $m(A \otimes B) \subset A$ and $m(B \otimes A) \subset A$. 

	\begin{Definition}[Coalgebra homomorphism]
		Using duality, a linear map $g\colon C \to D$ is a \emph{coalgebra homomorphism} if the following diagrams commute:
		\begin{align*}
			\xymatrix{
				C \otimes C \ar[r]^-{g \otimes g} & D \otimes D \\
				C \ar[u]^-{\Delta_C} \ar[r]_-{g} & D \ar[u]_-{\Delta_D}
			} & &
			\xymatrix{
				C \ar[rr]^-{g} \ar[rd]_-{\epsilon_C} & & D \ar[ld]^-{\epsilon_D} \\
				& \mathbb K & 
			}
		\end{align*}
		The diagrams encode $\bqty{(g \otimes g)\cdot \Delta_C} \equiv \Delta_D\cdot g$ and $\epsilon_D \cdot g \equiv \epsilon_C$. Using Sweedler notation:
		\begin{align*}
			\bqty{(g \otimes g)\cdot \Delta_C}(c) & = \Delta_D\cdot g(c) \\
			\pqty{g \otimes g} \pqty{\sum_{(c)} c_{(1)} \otimes c_{(2)}} & = \sum_{g(c)} [g(c)]_{(1)} \otimes [g(c)]_{(2)} \\
			\sum_{(c)} g(c_{(1)}) \otimes g(c_{(2)}) & = \sum_{g(c)} [g(c)]_{(1)} \otimes [g(c)]_{(2)} \\
			\epsilon_C(c) & = \epsilon_D[g(c)]
		\end{align*}
	\end{Definition}

	\begin{Definition}[Subcoalgebras]
		Let $D$ be a coalgebra and $C \subseteq D$. Then $C$ is a \emph{subcoalgebra} if $\Delta_C(C) \subseteq C$.
	\end{Definition}
	More generally, $C$ is a \emph{two-sided coideal} if $\Delta_C(C) \subset C \otimes D + D \otimes C$.

	\subsubsection{Duality of Homomorphisms}

	\begin{Theorem}
		If $f\colon C \to D$ is a coalgebra homomorphism, then the dual map $f^*\colon C^* \to D^*$ is an algebra homomorphism.
	\end{Theorem}
	\begin{proof}
		Dualising the coalgebra homomorphism diagrams and inserting the multiplication and unitary duality commutative diagrams:
		\begin{align*}
		\xymatrix{
			D^* \otimes D^* \ar[dd]_-{m_D} \ar[rd]_-{\rho_D} \ar[rrr]^-{f^* \otimes f^*} & & & C^* \otimes C^* \ar[ld]^-{\rho_C} \ar[dd]^-{m_C} \\
			& \pqty{D \otimes D}^* \ar[r]^-{\pqty{f \otimes f}^*} \ar[ld]_-{\Delta^*_D} & \pqty{C \otimes C}^* \ar[rd]^-{\Delta^*_C} & \\
			D^* \ar[rrr]_-{f^*} & & & C^*
		}
		\end{align*}
		\begin{align*}
			\xymatrix{
			D^* \ar[rrrr]^-{g^*} & & & & C^*  \\
			& & \mathbb K^* \ar[llu]_-{\epsilon^*_D} \ar[d]^-{\cong_{\mathbb K}} \ar[rru]^-{\epsilon^*_C} & & \\
			& & \mathbb K \ar[lluu]^-{u_{D^*}} \ar[rruu]_-{u_{C^*}} & & 
		}
		\end{align*}
		For the first diagram, the bottom, left and right diagrams commute as seen before. The top diagram indicates $(f \otimes f)^* \cdot \rho_D \equiv \rho_c \cdot f^* \otimes f^*$, which can be checked using inner product notation. The second diagram can also be checked similarly.
	\end{proof}
	Similarly, if the map $f\colon A \to B$, where $A$ and $B$ are \emph{finite-dimensional algebras}, is an algebra homomorphism, then $f^* \colon B^* \to A^*$ is a coalgebra homomorphism. 
\end{document}
